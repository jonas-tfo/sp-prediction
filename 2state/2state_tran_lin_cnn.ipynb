{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b1192d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b1192d4",
        "outputId": "c21527fd-35b1-44a7-88ba-6ad8a4db79e6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score, matthews_corrcoef, accuracy_score\n",
        "from sklearn.utils import resample\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "DEVICE = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MODEL_NAME = \"Rostlab/prot_bert\"\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# Hyperparameters\n",
        "NUM_CLASSES = 2  # Binary classification (0: no signal peptide, 1: signal peptide)\n",
        "MAX_LENGTH = 70 # max sequence has len 70 in unpartitioned dataset\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "LR = 0.001\n",
        "WINDOW_SIZE = 35  # sliding window (odd because model predicts center residue)\n",
        "STRIDE = 1  # Step size for sliding window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "181f6793",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "181f6793",
        "outputId": "86335777-4095-4365-9ac8-dbcaff2fd421"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/PBLRost/\"\n",
        "FASTA_PATH = os.path.join(DRIVE_PATH, \"data/complete_set_unpartitioned.fasta\")\n",
        "MODEL_PATH = os.path.join(DRIVE_PATH, \"models/2state_tran_lin_cnn.pt\")\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME, do_lower_case=False)\n",
        "encoder = BertModel.from_pretrained(MODEL_NAME)\n",
        "encoder.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ce93383",
      "metadata": {
        "id": "6ce93383"
      },
      "outputs": [],
      "source": [
        "def get_protbert_window_embeddings(windows, batch_size=16):\n",
        "    \"\"\"\n",
        "    Output shape: (num_windows, window_size, embedding_dim)\n",
        "    \"\"\"\n",
        "    all_embeddings = []\n",
        "    formatted = [\" \".join(list(window)) for window in windows] # needed for tokenization\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(formatted), batch_size)):\n",
        "            batch_seqs = formatted[i:i+batch_size]\n",
        "            encoded = tokenizer(batch_seqs, return_tensors=\"pt\", padding=True, truncation=True, max_length=MAX_LENGTH)\n",
        "\n",
        "            input_ids = encoded['input_ids'].to(DEVICE)\n",
        "            attention_mask = encoded['attention_mask'].to(DEVICE)\n",
        "\n",
        "            outputs = encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            # outputs.last_hidden_state: (batch, seq_len, emb_dim)\n",
        "            # Remove [CLS] and [SEP] tokens if present\n",
        "            for j, seq in enumerate(batch_seqs):\n",
        "                seq_len = len(seq.replace(\" \", \"\"))\n",
        "                # Find where the actual window ends (excluding padding tokens)\n",
        "                emb = outputs.last_hidden_state[j, 1:seq_len+1, :].cpu().numpy()  # skip [CLS], take only window\n",
        "                all_embeddings.append(emb)\n",
        "\n",
        "    return np.stack(all_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63ba15f2",
      "metadata": {
        "id": "63ba15f2"
      },
      "outputs": [],
      "source": [
        "def create_sliding_windows(sequence, labels, window_size, stride=1):\n",
        "    \"\"\"Create sliding windows from sequence and corresponding labels\"\"\"\n",
        "    windows = []\n",
        "    window_labels = []\n",
        "    positions = []\n",
        "\n",
        "    # Pad sequence for edge cases\n",
        "    pad_size = window_size // 2 # so starts classification after padding, at first real encoding\n",
        "    padded_seq = 'X' * pad_size + sequence + 'X' * pad_size\n",
        "    padded_labels = [0] * pad_size + labels + [0] * pad_size\n",
        "\n",
        "    # Create sliding windows\n",
        "    for i in range(0, len(sequence), stride):\n",
        "        start_idx = i\n",
        "        end_idx = i + window_size\n",
        "\n",
        "        if end_idx <= len(padded_seq):\n",
        "            window_seq = padded_seq[start_idx:end_idx]\n",
        "            # Label for the center position of the window\n",
        "            center_idx = start_idx + pad_size # residue to predict\n",
        "            if center_idx < len(padded_labels):\n",
        "                center_label = padded_labels[center_idx]\n",
        "\n",
        "                windows.append(window_seq)\n",
        "                window_labels.append(center_label)\n",
        "                positions.append(i)  # Original position in sequence\n",
        "\n",
        "    return windows, window_labels, positions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "064304e2",
      "metadata": {
        "id": "064304e2"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_data(fasta_path):\n",
        "    \"\"\"Load FASTA data and preprocess for sliding window approach\"\"\"\n",
        "    records = []\n",
        "\n",
        "    with open(fasta_path, \"r\") as f:\n",
        "        current_record = None\n",
        "        for line in f:\n",
        "            if line.startswith(\">\"):\n",
        "                if current_record is not None:\n",
        "                    if current_record[\"sequence\"] is not None and current_record[\"label\"] is not None:\n",
        "                        records.append(current_record)\n",
        "\n",
        "                uniprot_ac, kingdom, type_ = line[1:].strip().split(\"|\")\n",
        "                current_record = {\n",
        "                    \"uniprot_ac\": uniprot_ac,\n",
        "                    \"kingdom\": kingdom,\n",
        "                    \"type\": type_,\n",
        "                    \"sequence\": None,\n",
        "                    \"label\": None\n",
        "                }\n",
        "            else:\n",
        "                if current_record[\"sequence\"] is None:\n",
        "                    current_record[\"sequence\"] = line.strip()\n",
        "                elif current_record[\"label\"] is None:\n",
        "                    current_record[\"label\"] = line.strip()\n",
        "\n",
        "        # Add last record\n",
        "        if current_record is not None:\n",
        "            if current_record[\"sequence\"] is not None and current_record[\"label\"] is not None:\n",
        "                records.append(current_record)\n",
        "\n",
        "    print(f\"Total records loaded: {len(records)}\")\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df_raw = pd.DataFrame(records)\n",
        "\n",
        "    # Filter out sequences with 'P' in labels (if needed)\n",
        "    df = df_raw[~df_raw[\"label\"].str.contains(\"P\")]\n",
        "\n",
        "    # Map signal peptide types to binary classification\n",
        "    df[\"has_signal_peptide\"] = df[\"type\"].map({\n",
        "        \"NO_SP\": 0,\n",
        "        \"LIPO\": 1,\n",
        "        \"SP\": 1,\n",
        "        \"TAT\": 1,\n",
        "        \"TATLIPO\": 1\n",
        "    })\n",
        "\n",
        "    # Balance the dataset at sequence level first\n",
        "    df_majority = df[df[\"has_signal_peptide\"] == 0]\n",
        "    df_minority = df[df[\"has_signal_peptide\"] == 1]\n",
        "\n",
        "    if not df_minority.empty and not df_majority.empty:\n",
        "\n",
        "        n_samples = min(len(df_majority), 5000) # Limit samples to 5000 to prevent high ram usage\n",
        "        df_majority_sampled = resample(\n",
        "            df_majority,\n",
        "            replace=False, # sample without replacement\n",
        "            n_samples=n_samples,\n",
        "            random_state=42\n",
        "        )\n",
        "        df_balanced = pd.concat([df_majority_sampled, df_minority]) # Include all minority samples\n",
        "    else:\n",
        "        df_balanced = df.copy()\n",
        "\n",
        "\n",
        "    # Convert residue-level labels to binary\n",
        "    label_map = {'S': 1, 'T': 1, 'L': 1, 'I': 0, 'M': 0, 'O': 0}\n",
        "\n",
        "    # Create sliding windows for all sequences\n",
        "    all_windows = []\n",
        "    all_labels = []\n",
        "    all_seq_ids = []\n",
        "\n",
        "    for idx, row in df_balanced.iterrows():\n",
        "        sequence = row[\"sequence\"]\n",
        "        label_string = row[\"label\"]\n",
        "\n",
        "        # Convert label string to binary array\n",
        "        residue_labels = [label_map.get(c, 0) for c in label_string]\n",
        "\n",
        "        # Skip sequences where label length doesn't match sequence length\n",
        "        if len(residue_labels) != len(sequence):\n",
        "            print(\"A sequence length is not equal to the label length\")\n",
        "            continue\n",
        "\n",
        "        # Create sliding windows for this sequence\n",
        "        windows, window_labels, positions = create_sliding_windows(\n",
        "            sequence, residue_labels, WINDOW_SIZE, STRIDE\n",
        "        )\n",
        "\n",
        "        all_windows.extend(windows)\n",
        "        all_labels.extend(window_labels)\n",
        "        all_seq_ids.extend([idx] * len(windows))\n",
        "\n",
        "    print(f\"Total windows created: {len(all_windows)}\")\n",
        "    print(f\"Signal peptide windows: {sum(all_labels)}\")\n",
        "    print(f\"Non-signal peptide windows: {len(all_labels) - sum(all_labels)}\")\n",
        "\n",
        "    return all_windows, all_labels, all_seq_ids, df_balanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "408cc6b7",
      "metadata": {
        "id": "408cc6b7"
      },
      "outputs": [],
      "source": [
        "class LazySlidingWindowDataset(Dataset):\n",
        "    def __init__(self, embeddings_path, labels_path, indices):\n",
        "        self.embeddings_path = embeddings_path\n",
        "        self.labels_path = labels_path\n",
        "        self.indices = indices # Indices corresponding to the split (train, val, or test)\n",
        "\n",
        "        # Load the full embeddings and labels once\n",
        "        self.all_embeddings = np.load(self.embeddings_path, mmap_mode='r') # Use mmap_mode to avoid loading everything into memory\n",
        "        self.all_labels = np.load(self.labels_path, mmap_mode='r')\n",
        "\n",
        "        # Ensure indices are within bounds (should be handled by splitting logic, but good practice)\n",
        "        if max(indices) >= len(self.all_labels) or min(indices) < 0:\n",
        "             raise ValueError(\"Indices are out of bounds for the loaded data.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the index in the original full dataset\n",
        "        original_idx = self.indices[idx]\n",
        "\n",
        "        # Load the specific embedding and label using the original index\n",
        "        # Slicing with numpy arrays loaded via mmap_mode='r' is efficient\n",
        "        embedding = self.all_embeddings[original_idx]\n",
        "        label = self.all_labels[original_idx]\n",
        "\n",
        "        return {\n",
        "            'window': torch.tensor(embedding, dtype=torch.float32),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c777e161",
      "metadata": {
        "id": "c777e161"
      },
      "outputs": [],
      "source": [
        "class CNNLSTMSignalPeptideClassifier(nn.Module):\n",
        "    def __init__(self, window_size, num_aa, hidden_dim=128, num_layers=2,\n",
        "                 cnn_channels=[64, 32], lstm_hidden=64, lstm_layers=2,\n",
        "                 use_bidirectional=True, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.window_size = window_size\n",
        "        self.num_aa = num_aa\n",
        "        self.use_bidirectional = use_bidirectional\n",
        "        self.lstm_hidden = lstm_hidden\n",
        "        self.lstm_layers = lstm_layers\n",
        "\n",
        "        # CNN layers for local pattern detection\n",
        "        self.conv_layers = nn.ModuleList()\n",
        "        in_channels = num_aa\n",
        "\n",
        "        for out_channels in cnn_channels:\n",
        "            self.conv_layers.append(nn.Sequential(\n",
        "                nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm1d(out_channels),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout)\n",
        "            ))\n",
        "            in_channels = out_channels\n",
        "\n",
        "        # LSTM layers for sequential dependencies\n",
        "        # Input to LSTM: [batch_size, seq_len, features]\n",
        "        lstm_input_size = cnn_channels[-1]  # Last CNN output channels\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=lstm_input_size,\n",
        "            hidden_size=lstm_hidden,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if lstm_layers > 1 else 0,\n",
        "            bidirectional=use_bidirectional\n",
        "        )\n",
        "\n",
        "        # Calculate LSTM output size\n",
        "        lstm_output_size = lstm_hidden * (2 if use_bidirectional else 1)\n",
        "\n",
        "        # Attention mechanism to focus on important positions\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(lstm_output_size, lstm_output_size // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(lstm_output_size // 2, 1)\n",
        "        )\n",
        "\n",
        "        # Final classification layers\n",
        "        classifier_layers = []\n",
        "        in_dim = lstm_output_size\n",
        "\n",
        "        for _ in range(num_layers):\n",
        "            classifier_layers.extend([\n",
        "                nn.Linear(in_dim, hidden_dim),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout)\n",
        "            ])\n",
        "            in_dim = hidden_dim\n",
        "\n",
        "        # Binary classification output\n",
        "        classifier_layers.append(nn.Linear(hidden_dim, 1))\n",
        "        self.classifier = nn.Sequential(*classifier_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, window_size, num_aa]\n",
        "        batch_size, seq_len, num_features = x.size()\n",
        "\n",
        "        # need [batch_size, num_aa, window_size] for Conv1d\n",
        "        x = x.transpose(1, 2)  # [batch_size, num_aa, window_size]\n",
        "\n",
        "        # Apply CNN layers\n",
        "        for conv_layer in self.conv_layers:\n",
        "            x = conv_layer(x)\n",
        "\n",
        "        # need [batch_size, seq_len, features] for LSTM\n",
        "        x = x.transpose(1, 2)  # [batch_size, window_size, cnn_channels[-1]]\n",
        "\n",
        "        # LSTM processing\n",
        "        lstm_out, (hidden, cell) = self.lstm(x)\n",
        "        # lstm_out: [batch_size, seq_len, lstm_hidden * directions]\n",
        "\n",
        "        # Apply attention mechanism\n",
        "        attention_weights = self.attention(lstm_out)  # [batch_size, seq_len, 1]\n",
        "        attention_weights = F.softmax(attention_weights, dim=1)\n",
        "\n",
        "        # Weighted sum of LSTM outputs\n",
        "        attended_output = torch.sum(lstm_out * attention_weights, dim=1)\n",
        "        # attended_output: [batch_size, lstm_hidden * directions]\n",
        "\n",
        "        # Final classification\n",
        "        logits = self.classifier(attended_output)\n",
        "        return logits.squeeze(-1)  # Remove last dimension\n",
        "\n",
        "\n",
        "class CNNLSTMSignalPeptideClassifierV2(nn.Module):\n",
        "    \"\"\"Alternative version with different CNN-LSTM integration\"\"\"\n",
        "    def __init__(self, window_size, num_aa, hidden_dim=128, num_layers=2,\n",
        "                 cnn_channels=[64, 32], lstm_hidden=64, lstm_layers=1,\n",
        "                 use_bidirectional=True, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.window_size = window_size\n",
        "        self.num_aa = num_aa\n",
        "\n",
        "        # CNN feature extractor\n",
        "        self.cnn_backbone = nn.Sequential(\n",
        "            # First conv block\n",
        "            nn.Conv1d(num_aa, cnn_channels[0], kernel_size=5, padding=2),\n",
        "            nn.BatchNorm1d(cnn_channels[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            # Second conv block\n",
        "            nn.Conv1d(cnn_channels[0], cnn_channels[1], kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(cnn_channels[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            # Third conv block\n",
        "            nn.Conv1d(cnn_channels[1], cnn_channels[1], kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(cnn_channels[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        # LSTM for sequential modeling\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=cnn_channels[-1],\n",
        "            hidden_size=lstm_hidden,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if lstm_layers > 1 else 0,\n",
        "            bidirectional=use_bidirectional\n",
        "        )\n",
        "\n",
        "        # Calculate dimensions\n",
        "        lstm_output_size = lstm_hidden * (2 if use_bidirectional else 1)\n",
        "\n",
        "        # Global pooling options\n",
        "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
        "\n",
        "        # Classification head\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(lstm_output_size, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim // 2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, window_size, num_aa]\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # CNN feature extraction\n",
        "        x = x.transpose(1, 2)  # [batch_size, num_aa, window_size]\n",
        "        cnn_features = self.cnn_backbone(x)\n",
        "\n",
        "        # Prepare for LSTM\n",
        "        x = cnn_features.transpose(1, 2)  # [batch_size, window_size, features]\n",
        "\n",
        "        # LSTM processing\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "\n",
        "        # Global pooling over sequence dimension\n",
        "        lstm_out = lstm_out.transpose(1, 2)  # [batch_size, features, seq_len]\n",
        "        pooled = self.global_pool(lstm_out).squeeze(-1)  # [batch_size, features]\n",
        "\n",
        "        # Classification\n",
        "        logits = self.classifier(pooled)\n",
        "        return logits.squeeze(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76c2361d",
      "metadata": {
        "id": "76c2361d"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, num_epochs, device,\n",
        "                        lr=0.001, weight_decay=1e-5, patience=5):\n",
        "    \"\"\"Enhanced training function with gradient clipping and better scheduling\"\"\"\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # More sophisticated learning rate scheduling\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', patience=patience, factor=0.5, verbose=True\n",
        "    )\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_batches = 0\n",
        "\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        for batch in progress_bar:\n",
        "            windows = batch['window'].to(device)\n",
        "            labels = batch['label'].to(device).float()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            try:\n",
        "                logits = model(windows)\n",
        "                loss = criterion(logits, labels)\n",
        "\n",
        "                loss.backward()\n",
        "\n",
        "                # Gradient clipping to prevent exploding gradients\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item()\n",
        "                train_batches += 1\n",
        "\n",
        "                progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                print(f\"Error in training batch: {e}\")\n",
        "                continue\n",
        "\n",
        "        if train_batches == 0:\n",
        "            print(\"No successful training batches!\")\n",
        "            break\n",
        "\n",
        "        avg_train_loss = train_loss / train_batches\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_batches = 0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                windows = batch['window'].to(device)\n",
        "                labels = batch['label'].to(device).float()\n",
        "\n",
        "                try:\n",
        "                    logits = model(windows)\n",
        "                    loss = criterion(logits, labels)\n",
        "\n",
        "                    val_loss += loss.item()\n",
        "                    val_batches += 1\n",
        "\n",
        "                    # Calculate accuracy\n",
        "                    predictions = (torch.sigmoid(logits) > 0.5).float()\n",
        "                    val_correct += (predictions == labels).sum().item()\n",
        "                    val_total += labels.size(0)\n",
        "\n",
        "                except RuntimeError as e:\n",
        "                    print(f\"Error in validation batch: {e}\")\n",
        "                    continue\n",
        "\n",
        "        if val_batches == 0:\n",
        "            print(\"No successful validation batches!\")\n",
        "            break\n",
        "\n",
        "        avg_val_loss = val_loss / val_batches\n",
        "        val_accuracy = val_correct / val_total\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        # Learning rate scheduling\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}, \"\n",
        "              f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
        "\n",
        "        # Early stopping and best model saving\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), MODEL_PATH)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience * 2:  # More patience for complex model\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "    return train_losses, val_losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6713138b",
      "metadata": {
        "id": "6713138b"
      },
      "outputs": [],
      "source": [
        "# compute percentage of false predicted labels\n",
        "def sequence_level_accuracy(labels, predictions):\n",
        "    \"\"\"Compute the accuracy of individual window predictions.\"\"\"\n",
        "    correct = 0\n",
        "    total = len(labels) # Total number of windows\n",
        "\n",
        "    # Ensure labels and predictions have the same length\n",
        "    if len(labels) != len(predictions):\n",
        "        print(\"Warning: Length of labels and predictions do not match.\")\n",
        "        # Adjust total to the minimum length if lengths differ\n",
        "        total = min(len(labels), len(predictions))\n",
        "        labels = labels[:total]\n",
        "        predictions = predictions[:total]\n",
        "\n",
        "\n",
        "    for pred, label in zip(predictions, labels):\n",
        "        # Now comparing individual predictions and labels\n",
        "        if pred == label:\n",
        "            correct += 1\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cfdfb0f",
      "metadata": {
        "id": "0cfdfb0f"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader, device):\n",
        "    \"\"\"Evaluate the sliding window model\"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "            windows = batch['window'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            logits = model(windows)\n",
        "            probabilities = torch.sigmoid(logits)\n",
        "            predictions = (probabilities > 0.5).long()\n",
        "\n",
        "            all_preds.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_probs.extend(probabilities.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=['No Signal', 'Signal']))\n",
        "\n",
        "    f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
        "    f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
        "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    seq_acc = sequence_level_accuracy(all_labels, all_preds)\n",
        "\n",
        "    print(f\"F1 Score (weighted): {f1_weighted:.4f}\")\n",
        "    print(f\"F1 Score (macro): {f1_macro:.4f}\")\n",
        "    print(f\"Matthews Correlation Coefficient: {mcc:.4f}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Sequence-level Accuracy: {seq_acc:.4f}\")\n",
        "\n",
        "    return all_preds, all_labels, all_probs\n",
        "\n",
        "def predict_sequence(model, sequence, window_size, device, threshold=0.5):\n",
        "    \"\"\"Predict signal peptide positions for a full sequence\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Create dummy labels (we don't need them for prediction)\n",
        "    dummy_labels = [0] * len(sequence)\n",
        "\n",
        "    # Create sliding windows\n",
        "    windows, _, positions = create_sliding_windows(sequence, dummy_labels, window_size, stride=1)\n",
        "\n",
        "    # Encode windows\n",
        "    encoded_windows = get_protbert_window_embeddings(windows)\n",
        "\n",
        "    predictions = []\n",
        "    probabilities = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for encoded_window in encoded_windows:\n",
        "            window_tensor = torch.tensor(encoded_window, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "            logit = model(window_tensor)\n",
        "            prob = torch.sigmoid(logit).item()\n",
        "            pred = int(prob > threshold)\n",
        "\n",
        "            predictions.append(pred)\n",
        "            probabilities.append(prob)\n",
        "\n",
        "    return predictions, probabilities, positions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8ad5489",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8ad5489",
        "outputId": "876559aa-d45b-4745-b619-cadf70ade227"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess data with sliding windows\n",
        "# This will create windows and labels but NOT encode them yet\n",
        "windows, labels, seq_ids, df_balanced = load_and_preprocess_data(FASTA_PATH)\n",
        "\n",
        "\n",
        "\n",
        "# --- Step 1: Pre-encode and Save Embeddings ---\n",
        "print(\"Encoding all windows...\")\n",
        "# Process windows in batches to manage memory during encoding\n",
        "all_embeddings = get_protbert_window_embeddings(windows)\n",
        "\n",
        "# Save embeddings and labels to disk\n",
        "embeddings_path = os.path.join(DRIVE_PATH, \"all_window_embeddings.npy\")\n",
        "labels_path = os.path.join(DRIVE_PATH, \"all_window_labels.npy\")\n",
        "df_balanced_path = os.path.join(DRIVE_PATH, \"df_balanced.csv\") # Save the balanced dataframe for later use if needed\n",
        "\n",
        "np.save(embeddings_path, all_embeddings)\n",
        "np.save(labels_path, np.array(labels))\n",
        "df_balanced.to_csv(df_balanced_path, index=False)\n",
        "\n",
        "print(f\"Embeddings saved to {embeddings_path}\")\n",
        "print(f\"Labels saved to {labels_path}\")\n",
        "print(f\"Balanced DataFrame saved to {df_balanced_path}\")\n",
        "\n",
        "# --- Step 2 & 3: Create Dataset instances using LazySlidingWindowDataset and Update Training/Evaluation ---\n",
        "\n",
        "# Split indices based on unique sequence IDs to avoid data leakage\n",
        "unique_seq_ids = list(df_balanced.index.unique()) # Use index from df_balanced\n",
        "train_seq_ids, temp_seq_ids = train_test_split(unique_seq_ids, test_size=0.2, random_state=42)\n",
        "val_seq_ids, test_seq_ids = train_test_split(temp_seq_ids, test_size=0.5, random_state=42) # 0.5 of 0.2 = 0.1 test size\n",
        "\n",
        "# Get indices corresponding to each split based on the original df_balanced index\n",
        "train_indices = [i for i, seq_id in enumerate(seq_ids) if seq_id in train_seq_ids]\n",
        "val_indices = [i for i, seq_id in enumerate(seq_ids) if seq_id in val_seq_ids]\n",
        "test_indices = [i for i, seq_id in enumerate(seq_ids) if seq_id in test_seq_ids]\n",
        "\n",
        "print(f\"\\nTrain windows (indices): {len(train_indices)}\")\n",
        "print(f\"Validation windows (indices): {len(val_indices)}\")\n",
        "print(f\"Test windows (indices): {len(test_indices)}\")\n",
        "\n",
        "# Create datasets and loaders using the saved files and indices\n",
        "train_dataset = LazySlidingWindowDataset(embeddings_path, labels_path, train_indices)\n",
        "val_dataset = LazySlidingWindowDataset(embeddings_path, labels_path, val_indices)\n",
        "test_dataset = LazySlidingWindowDataset(embeddings_path, labels_path, test_indices)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Initialize model (CNN version)\n",
        "model = CNNLSTMSignalPeptideClassifier(\n",
        "    WINDOW_SIZE, all_embeddings.shape[-1], hidden_dim=128, num_layers=2 # Use embedding dim from the saved file\n",
        ").to(DEVICE)\n",
        "\n",
        "print(f\"\\nModel parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "# Train model\n",
        "train_losses, val_losses = train_model(model, train_loader, val_loader, EPOCHS, DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75e0113a",
      "metadata": {
        "id": "75e0113a"
      },
      "outputs": [],
      "source": [
        "# Load best model for evaluation\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
        "\n",
        "# Evaluate model\n",
        "print(\"\\nFinal Evaluation:\")\n",
        "predictions, labels_true, probabilities = evaluate_model(model, test_loader, DEVICE)\n",
        "\n",
        "# Plot training curves\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training Curves')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(probabilities, bins=50, alpha=0.7, label='All Predictions')\n",
        "plt.xlabel('Prediction Probability')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Prediction Probability Distribution')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v-MEP30AvNtE",
      "metadata": {
        "id": "v-MEP30AvNtE"
      },
      "outputs": [],
      "source": [
        "# Example: Predict on a sample sequence\n",
        "sample_sequence = \"MKKTAIAIAVALAGFATVAQAAPKDNTWYTGAKLGHLQGPVRGVNPTTNAASMKNFTNDIKKEDTSFVTLDAAQ\"\n",
        "print(f\"\\nExample prediction for sequence: {sample_sequence}\")\n",
        "preds, probs, pos = predict_sequence(model, sample_sequence, WINDOW_SIZE, DEVICE)\n",
        "\n",
        "print(\"Position\\tAA\\tProbability\\tPrediction\")\n",
        "for i, (pred, prob, position) in enumerate(zip(preds, probs, pos)):\n",
        "    aa = sample_sequence[position] if position < len(sample_sequence) else 'X'\n",
        "    print(f\"{position:3d}\\t{aa}\\t{prob:.3f}\\t\\t{'Signal' if pred else 'No Signal'}\")\n",
        "\n",
        "# Save final model\n",
        "torch.save(model.state_dict(), MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "293b779c",
      "metadata": {
        "id": "293b779c"
      },
      "outputs": [],
      "source": [
        "def get_protbert_window_embeddings(windows, batch_size=16, output_path=None, embedding_dim=1024):\n",
        "    \"\"\"\n",
        "    Output shape: (num_windows, window_size, embedding_dim)\n",
        "    If output_path is provided, saves embeddings to a memory-mapped file.\n",
        "    Otherwise, returns a concatenated NumPy array.\n",
        "    \"\"\"\n",
        "    formatted = [\" \".join(list(window)) for window in windows] # needed for tokenization\n",
        "    num_windows = len(formatted)\n",
        "    window_size = len(windows[0]) # Assuming all windows have the same size after padding/truncation\n",
        "\n",
        "    if output_path:\n",
        "        # Initialize memory-mapped array\n",
        "        # Need to estimate the exact sequence length after tokenization and potential padding/truncation\n",
        "        # A safer approach is to determine the max length after tokenization or use the known MAX_LENGTH\n",
        "        # Let's use MAX_LENGTH here, assuming it's the effective sequence length after tokenization and padding\n",
        "        print(f\"Initializing memory-mapped file at {output_path} with shape ({num_windows}, {MAX_LENGTH}, {embedding_dim})\")\n",
        "        all_embeddings_mmap = np.memmap(output_path, dtype='float32', mode='w+', shape=(num_windows, MAX_LENGTH, embedding_dim))\n",
        "\n",
        "    all_embeddings_list = [] # Keep this for the case where output_path is None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, num_windows, batch_size)):\n",
        "            batch_seqs = formatted[i:i+batch_size]\n",
        "            encoded = tokenizer(batch_seqs, return_tensors=\"pt\", padding=True, truncation=True, max_length=MAX_LENGTH)\n",
        "\n",
        "            input_ids = encoded['input_ids'].to(DEVICE)\n",
        "            attention_mask = encoded['attention_mask'].to(DEVICE)\n",
        "\n",
        "            outputs = encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            batch_embeddings = outputs.last_hidden_state.cpu().numpy() # (batch, seq_len, emb_dim)\n",
        "\n",
        "            # prot_bert adds [CLS] and [SEP]. We need to slice to get the actual window embeddings\n",
        "            # The actual sequence length before padding can vary within a batch due to truncation\n",
        "            # and the original un-padded window length.\n",
        "            # However, for consistent window embeddings of size MAX_LENGTH, we can just slice\n",
        "            # from index 1 up to MAX_LENGTH + 1 (to exclude CLS and include MAX_LENGTH tokens).\n",
        "            # If padding is present, the embeddings for padding tokens will be there but won't affect\n",
        "            # the actual sequence residues.\n",
        "            processed_batch_embeddings = batch_embeddings[:, 1:MAX_LENGTH+1, :] # Remove [CLS] token embedding\n",
        "\n",
        "            if output_path:\n",
        "                # Write directly to the memory-mapped array\n",
        "                end_idx = min(i + batch_size, num_windows)\n",
        "                all_embeddings_mmap[i:end_idx] = processed_batch_embeddings[:end_idx-i] # Handle the last batch size\n",
        "\n",
        "            else:\n",
        "                # Append to the list if not saving to file\n",
        "                for emb in processed_batch_embeddings:\n",
        "                    all_embeddings_list.append(emb)\n",
        "\n",
        "    if output_path:\n",
        "        # Ensure all changes are written to disk\n",
        "        all_embeddings_mmap.flush()\n",
        "        # The memory-mapped file will be returned. It behaves like a numpy array.\n",
        "        return all_embeddings_mmap\n",
        "    else:\n",
        "        # Return concatenated array\n",
        "        return np.stack(all_embeddings_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1960601",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "b1960601",
        "outputId": "72e07f2f-b233-403d-fe75-92ac6ec9369a"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess data with sliding windows\n",
        "# This will create windows and labels but NOT encode them yet\n",
        "windows, labels, seq_ids, df_balanced = load_and_preprocess_data(FASTA_PATH)\n",
        "\n",
        "# --- Step 1: Pre-encode and Save Embeddings ---\n",
        "print(\"Encoding all windows...\")\n",
        "# Process windows in batches and save directly to disk\n",
        "embeddings_path = os.path.join(DRIVE_PATH, \"all_window_embeddings.npy\")\n",
        "labels_path = os.path.join(DRIVE_PATH, \"all_window_labels.npy\")\n",
        "df_balanced_path = os.path.join(DRIVE_PATH, \"df_balanced.csv\") # Save the balanced dataframe for later use if needed\n",
        "\n",
        "# Assuming the first window's embedding size will be consistent\n",
        "dummy_encoding = get_protbert_window_embeddings([windows[0]])\n",
        "embedding_dim = dummy_encoding.shape[-1]\n",
        "del dummy_encoding # Free up memory\n",
        "\n",
        "# Use the modified function to save embeddings incrementally\n",
        "all_embeddings = get_protbert_window_embeddings(\n",
        "    windows,\n",
        "    batch_size=BATCH_SIZE, # Use same batch size as for training/inference\n",
        "    output_path=embeddings_path,\n",
        "    embedding_dim=embedding_dim\n",
        ")\n",
        "\n",
        "# Save labels and balanced dataframe\n",
        "np.save(labels_path, np.array(labels))\n",
        "df_balanced.to_csv(df_balanced_path, index=False)\n",
        "\n",
        "print(f\"Embeddings saved to {embeddings_path}\")\n",
        "print(f\"Labels saved to {labels_path}\")\n",
        "print(f\"Balanced DataFrame saved to {df_balanced_path}\")\n",
        "\n",
        "# --- Step 2 & 3: Create Dataset instances using LazySlidingWindowDataset and Update Training/Evaluation ---\n",
        "\n",
        "# Split indices based on unique sequence IDs to avoid data leakage\n",
        "unique_seq_ids = list(df_balanced.index.unique()) # Use index from df_balanced\n",
        "train_seq_ids, temp_seq_ids = train_test_split(unique_seq_ids, test_size=0.2, random_state=42)\n",
        "val_seq_ids, test_seq_ids = train_test_split(temp_seq_ids, test_size=0.5, random_state=42) # 0.5 of 0.2 = 0.1 test size\n",
        "\n",
        "# Get indices corresponding to each split based on the original df_balanced index\n",
        "train_indices = [i for i, seq_id in enumerate(seq_ids) if seq_id in train_seq_ids]\n",
        "val_indices = [i for i, seq_id in enumerate(seq_ids) if seq_id in val_seq_ids]\n",
        "test_indices = [i for i, seq_id in enumerate(seq_ids) if seq_id in test_seq_ids]\n",
        "\n",
        "print(f\"\\nTrain windows (indices): {len(train_indices)}\")\n",
        "print(f\"Validation windows (indices): {len(val_indices)}\")\n",
        "print(f\"Test windows (indices): {len(test_indices)}\")\n",
        "\n",
        "# Create datasets and loaders using the saved files and indices\n",
        "train_dataset = LazySlidingWindowDataset(embeddings_path, labels_path, train_indices)\n",
        "val_dataset = LazySlidingWindowDataset(embeddings_path, labels_path, val_indices)\n",
        "test_dataset = LazySlidingWindowDataset(embeddings_path, labels_path, test_indices)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Initialize model (CNN version)\n",
        "# Use the embedding dimension determined from the dummy encoding\n",
        "model = CNNLSTMSignalPeptideClassifier(\n",
        "    WINDOW_SIZE, embedding_dim, hidden_dim=128, num_layers=2\n",
        ").to(DEVICE)\n",
        "\n",
        "print(f\"\\nModel parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "# Train model\n",
        "train_losses, val_losses = train_model(model, train_loader, val_loader, EPOCHS, DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17a06249",
      "metadata": {
        "id": "17a06249"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because the `load_and_preprocess_data` function was not executed. Re-execute the cell containing this function definition and the subsequent cells that depend on it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "os6gtcB0-0q9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "os6gtcB0-0q9",
        "outputId": "95a423cb-6b33-438b-a3e1-e17c234199e4"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_data(fasta_path):\n",
        "    \"\"\"Load FASTA data and preprocess for sliding window approach\"\"\"\n",
        "    records = []\n",
        "\n",
        "    with open(fasta_path, \"r\") as f:\n",
        "        current_record = None\n",
        "        for line in f:\n",
        "            if line.startswith(\">\"):\n",
        "                if current_record is not None:\n",
        "                    if current_record[\"sequence\"] is not None and current_record[\"label\"] is not None:\n",
        "                        records.append(current_record)\n",
        "\n",
        "                uniprot_ac, kingdom, type_ = line[1:].strip().split(\"|\")\n",
        "                current_record = {\n",
        "                    \"uniprot_ac\": uniprot_ac,\n",
        "                    \"kingdom\": kingdom,\n",
        "                    \"type\": type_,\n",
        "                    \"sequence\": None,\n",
        "                    \"label\": None\n",
        "                }\n",
        "            else:\n",
        "                if current_record[\"sequence\"] is None:\n",
        "                    current_record[\"sequence\"] = line.strip()\n",
        "                elif current_record[\"label\"] is None:\n",
        "                    current_record[\"label\"] = line.strip()\n",
        "\n",
        "        # Add last record\n",
        "        if current_record is not None:\n",
        "            if current_record[\"sequence\"] is not None and current_record[\"label\"] is not None:\n",
        "                records.append(current_record)\n",
        "\n",
        "    print(f\"Total records loaded: {len(records)}\")\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df_raw = pd.DataFrame(records)\n",
        "\n",
        "    # Filter out sequences with 'P' in labels (if needed)\n",
        "    df = df_raw[~df_raw[\"label\"].str.contains(\"P\")]\n",
        "\n",
        "    # Map signal peptide types to binary classification\n",
        "    df[\"has_signal_peptide\"] = df[\"type\"].map({\n",
        "        \"NO_SP\": 0,\n",
        "        \"LIPO\": 1,\n",
        "        \"SP\": 1,\n",
        "        \"TAT\": 1,\n",
        "        \"TATLIPO\": 1\n",
        "    })\n",
        "\n",
        "    # Balance the dataset at sequence level first\n",
        "    df_majority = df[df[\"has_signal_peptide\"] == 0]\n",
        "    df_minority = df[df[\"has_signal_peptide\"] == 1]\n",
        "\n",
        "    if not df_minority.empty and not df_majority.empty:\n",
        "\n",
        "        n_samples = min(len(df_majority), 5000) # Limit samples to 5000 to prevent high ram usage\n",
        "        df_majority_sampled = resample(\n",
        "            df_majority,\n",
        "            replace=False, # sample without replacement\n",
        "            n_samples=n_samples,\n",
        "            random_state=42\n",
        "        )\n",
        "        df_balanced = pd.concat([df_majority_sampled, df_minority]) # Include all minority samples\n",
        "    else:\n",
        "        df_balanced = df.copy()\n",
        "\n",
        "\n",
        "    # Convert residue-level labels to binary\n",
        "    label_map = {'S': 1, 'T': 1, 'L': 1, 'I': 0, 'M': 0, 'O': 0}\n",
        "\n",
        "    # Create sliding windows for all sequences\n",
        "    all_windows = []\n",
        "    all_labels = []\n",
        "    all_seq_ids = []\n",
        "\n",
        "    for idx, row in df_balanced.iterrows():\n",
        "        sequence = row[\"sequence\"]\n",
        "        label_string = row[\"label\"]\n",
        "\n",
        "        # Convert label string to binary array\n",
        "        residue_labels = [label_map.get(c, 0) for c in label_string]\n",
        "\n",
        "        # Skip sequences where label length doesn't match sequence length\n",
        "        if len(residue_labels) != len(sequence):\n",
        "            print(\"A sequence length is not equal to the label length\")\n",
        "            continue\n",
        "\n",
        "        # Create sliding windows for this sequence\n",
        "        windows, window_labels, positions = create_sliding_windows(\n",
        "            sequence, residue_labels, WINDOW_SIZE, STRIDE\n",
        "        )\n",
        "\n",
        "        all_windows.extend(windows)\n",
        "        all_labels.extend(window_labels)\n",
        "        all_seq_ids.extend([idx] * len(windows))\n",
        "\n",
        "    print(f\"Total windows created: {len(all_windows)}\")\n",
        "    print(f\"Signal peptide windows: {sum(all_labels)}\")\n",
        "    print(f\"Non-signal peptide windows: {len(all_labels) - sum(all_labels)}\")\n",
        "\n",
        "    return all_windows, all_labels, all_seq_ids, df_balanced\n",
        "\n",
        "def get_protbert_window_embeddings(windows, batch_size=16, output_path=None, embedding_dim=1024):\n",
        "    \"\"\"\n",
        "    Output shape: (num_windows, window_size, embedding_dim)\n",
        "    If output_path is provided, saves embeddings to a memory-mapped file.\n",
        "    Otherwise, returns a concatenated NumPy array.\n",
        "    \"\"\"\n",
        "    formatted = [\" \".join(list(window)) for window in windows] # needed for tokenization\n",
        "    num_windows = len(formatted)\n",
        "    window_size = len(windows[0]) # Assuming all windows have the same size after padding/truncation\n",
        "\n",
        "    if output_path:\n",
        "        # Initialize memory-mapped array\n",
        "        # Need to estimate the exact sequence length after tokenization and potential padding/truncation\n",
        "        # A safer approach is to determine the max length after tokenization or use the known MAX_LENGTH\n",
        "        # Let's use MAX_LENGTH here, assuming it's the effective sequence length after tokenization and padding\n",
        "        print(f\"Initializing memory-mapped file at {output_path} with shape ({num_windows}, {MAX_LENGTH}, {embedding_dim})\")\n",
        "        all_embeddings_mmap = np.memmap(output_path, dtype='float32', mode='w+', shape=(num_windows, MAX_LENGTH, embedding_dim))\n",
        "\n",
        "    all_embeddings_list = [] # Keep this for the case where output_path is None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, num_windows, batch_size)):\n",
        "            batch_seqs = formatted[i:i+batch_size]\n",
        "            encoded = tokenizer(batch_seqs, return_tensors=\"pt\", padding=True, truncation=True, max_length=MAX_LENGTH)\n",
        "\n",
        "            input_ids = encoded['input_ids'].to(DEVICE)\n",
        "            attention_mask = encoded['attention_mask'].to(DEVICE)\n",
        "\n",
        "            outputs = encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            batch_embeddings = outputs.last_hidden_state.cpu().numpy() # (batch, seq_len, emb_dim)\n",
        "\n",
        "            # prot_bert adds [CLS] and [SEP]. We need to slice to get the actual window embeddings\n",
        "            # The actual sequence length before padding can vary within a batch due to truncation\n",
        "            # and the original un-padded window length.\n",
        "            # However, for consistent window embeddings of size MAX_LENGTH, we can just slice\n",
        "            # from index 1 up to MAX_LENGTH + 1 (to exclude CLS and include MAX_LENGTH tokens).\n",
        "            # If padding is present, the embeddings for padding tokens will be there but won't affect\n",
        "            # the actual sequence residues.\n",
        "            processed_batch_embeddings = batch_embeddings[:, 1:MAX_LENGTH+1, :] # Remove [CLS] token embedding\n",
        "\n",
        "            if output_path:\n",
        "                # Write directly to the memory-mapped array\n",
        "                end_idx = min(i + batch_size, num_windows)\n",
        "                all_embeddings_mmap[i:end_idx] = processed_batch_embeddings[:end_idx-i] # Handle the last batch size\n",
        "\n",
        "            else:\n",
        "                # Append to the list if not saving to file\n",
        "                for emb in processed_batch_embeddings:\n",
        "                    all_embeddings_list.append(emb)\n",
        "\n",
        "    if output_path:\n",
        "        # Ensure all changes are written to disk\n",
        "        all_embeddings_mmap.flush()\n",
        "        # The memory-mapped file will be returned. It behaves like a numpy array.\n",
        "        return all_embeddings_mmap\n",
        "    else:\n",
        "        # Return concatenated array\n",
        "        return np.stack(all_embeddings_list)\n",
        "\n",
        "class LazySlidingWindowDataset(Dataset):\n",
        "    def __init__(self, embeddings_path, labels_path, indices):\n",
        "        self.embeddings_path = embeddings_path\n",
        "        self.labels_path = labels_path\n",
        "        self.indices = indices # Indices corresponding to the split (train, val, or test)\n",
        "\n",
        "        # Load the full embeddings and labels once\n",
        "        self.all_embeddings = np.load(self.embeddings_path, mmap_mode='r') # Use mmap_mode to avoid loading everything into memory\n",
        "        self.all_labels = np.load(self.labels_path, mmap_mode='r')\n",
        "\n",
        "        # Ensure indices are within bounds (should be handled by splitting logic, but good practice)\n",
        "        if max(indices) >= len(self.all_labels) or min(indices) < 0:\n",
        "             raise ValueError(\"Indices are out of bounds for the loaded data.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the index in the original full dataset\n",
        "        original_idx = self.indices[idx]\n",
        "\n",
        "        # Load the specific embedding and label using the original index\n",
        "        # Slicing with numpy arrays loaded via mmap_mode='r' is efficient\n",
        "        embedding = self.all_embeddings[original_idx]\n",
        "        label = self.all_labels[original_idx]\n",
        "\n",
        "        return {\n",
        "            'window': torch.tensor(embedding, dtype=torch.float32),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "class CNNLSTMSignalPeptideClassifier(nn.Module):\n",
        "    def __init__(self, window_size, num_aa, hidden_dim=128, num_layers=2,\n",
        "                 cnn_channels=[64, 32], lstm_hidden=64, lstm_layers=2,\n",
        "                 use_bidirectional=True, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.window_size = window_size\n",
        "        self.num_aa = num_aa\n",
        "        self.use_bidirectional = use_bidirectional\n",
        "        self.lstm_hidden = lstm_hidden\n",
        "        self.lstm_layers = lstm_layers\n",
        "\n",
        "        # CNN layers for local pattern detection\n",
        "        self.conv_layers = nn.ModuleList()\n",
        "        in_channels = num_aa\n",
        "\n",
        "        for out_channels in cnn_channels:\n",
        "            self.conv_layers.append(nn.Sequential(\n",
        "                nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm1d(out_channels),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout)\n",
        "            ))\n",
        "            in_channels = out_channels\n",
        "\n",
        "        # LSTM layers for sequential dependencies\n",
        "        # Input to LSTM: [batch_size, seq_len, features]\n",
        "        lstm_input_size = cnn_channels[-1]  # Last CNN output channels\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=lstm_input_size,\n",
        "            hidden_size=lstm_hidden,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if lstm_layers > 1 else 0,\n",
        "            bidirectional=use_bidirectional\n",
        "        )\n",
        "\n",
        "        # Calculate LSTM output size\n",
        "        lstm_output_size = lstm_hidden * (2 if use_bidirectional else 1)\n",
        "\n",
        "        # Attention mechanism to focus on important positions\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(lstm_output_size, lstm_output_size // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(lstm_output_size // 2, 1)\n",
        "        )\n",
        "\n",
        "        # Final classification layers\n",
        "        classifier_layers = []\n",
        "        in_dim = lstm_output_size\n",
        "\n",
        "        for _ in range(num_layers):\n",
        "            classifier_layers.extend([\n",
        "                nn.Linear(in_dim, hidden_dim),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout)\n",
        "            ])\n",
        "            in_dim = hidden_dim\n",
        "\n",
        "        # Binary classification output\n",
        "        classifier_layers.append(nn.Linear(hidden_dim, 1))\n",
        "        self.classifier = nn.Sequential(*classifier_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, window_size, num_aa]\n",
        "        batch_size, seq_len, num_features = x.size()\n",
        "\n",
        "        # need [batch_size, num_aa, window_size] for Conv1d\n",
        "        x = x.transpose(1, 2)  # [batch_size, num_aa, window_size]\n",
        "\n",
        "        # Apply CNN layers\n",
        "        for conv_layer in self.conv_layers:\n",
        "            x = conv_layer(x)\n",
        "\n",
        "        # need [batch_size, seq_len, features] for LSTM\n",
        "        x = x.transpose(1, 2)  # [batch_size, window_size, cnn_channels[-1]]\n",
        "\n",
        "        # LSTM processing\n",
        "        lstm_out, (hidden, cell) = self.lstm(x)\n",
        "        # lstm_out: [batch_size, seq_len, lstm_hidden * directions]\n",
        "\n",
        "        # Apply attention mechanism\n",
        "        attention_weights = self.attention(lstm_out)  # [batch_size, seq_len, 1]\n",
        "        attention_weights = F.softmax(attention_weights, dim=1)\n",
        "\n",
        "        # Weighted sum of LSTM outputs\n",
        "        attended_output = torch.sum(lstm_out * attention_weights, dim=1)\n",
        "        # attended_output: [batch_size, lstm_hidden * directions]\n",
        "\n",
        "        # Final classification\n",
        "        logits = self.classifier(attended_output)\n",
        "        return logits.squeeze(-1)  # Remove last dimension\n",
        "\n",
        "\n",
        "class CNNLSTMSignalPeptideClassifierV2(nn.Module):\n",
        "    \"\"\"Alternative version with different CNN-LSTM integration\"\"\"\n",
        "    def __init__(self, window_size, num_aa, hidden_dim=128, num_layers=2,\n",
        "                 cnn_channels=[64, 32], lstm_hidden=64, lstm_layers=1,\n",
        "                 use_bidirectional=True, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.window_size = window_size\n",
        "        self.num_aa = num_aa\n",
        "\n",
        "        # CNN feature extractor\n",
        "        self.cnn_backbone = nn.Sequential(\n",
        "            # First conv block\n",
        "            nn.Conv1d(num_aa, cnn_channels[0], kernel_size=5, padding=2),\n",
        "            nn.BatchNorm1d(cnn_channels[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            # Second conv block\n",
        "            nn.Conv1d(cnn_channels[0], cnn_channels[1], kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(cnn_channels[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            # Third conv block\n",
        "            nn.Conv1d(cnn_channels[1], cnn_channels[1], kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(cnn_channels[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        # LSTM for sequential modeling\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=cnn_channels[-1],\n",
        "            hidden_size=lstm_hidden,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if lstm_layers > 1 else 0,\n",
        "            bidirectional=use_bidirectional\n",
        "        )\n",
        "\n",
        "        # Calculate dimensions\n",
        "        lstm_output_size = lstm_hidden * (2 if use_bidirectional else 1)\n",
        "\n",
        "        # Global pooling options\n",
        "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
        "\n",
        "        # Classification head\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(lstm_output_size, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim // 2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, window_size, num_aa]\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # CNN feature extraction\n",
        "        x = x.transpose(1, 2)  # [batch_size, num_aa, window_size]\n",
        "        cnn_features = self.cnn_backbone(x)\n",
        "\n",
        "        # Prepare for LSTM\n",
        "        x = cnn_features.transpose(1, 2)  # [batch_size, window_size, features]\n",
        "\n",
        "        # LSTM processing\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "\n",
        "        # Global pooling over sequence dimension\n",
        "        lstm_out = lstm_out.transpose(1, 2)  # [batch_size, features, seq_len]\n",
        "        pooled = self.global_pool(lstm_out).squeeze(-1)  # [batch_size, features]\n",
        "\n",
        "        # Classification\n",
        "        logits = self.classifier(pooled)\n",
        "        return logits.squeeze(-1)\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs, device,\n",
        "                        lr=0.001, weight_decay=1e-5, patience=5):\n",
        "    \"\"\"Enhanced training function with gradient clipping and better scheduling\"\"\"\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # More sophisticated learning rate scheduling\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', patience=patience, factor=0.5, verbose=True\n",
        "    )\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_batches = 0\n",
        "\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        for batch in progress_bar:\n",
        "            windows = batch['window'].to(device)\n",
        "            labels = batch['label'].to(device).float()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            try:\n",
        "                logits = model(windows)\n",
        "                loss = criterion(logits, labels)\n",
        "\n",
        "                loss.backward()\n",
        "\n",
        "                # Gradient clipping to prevent exploding gradients\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item()\n",
        "                train_batches += 1\n",
        "\n",
        "                progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                print(f\"Error in training batch: {e}\")\n",
        "                continue\n",
        "\n",
        "        if train_batches == 0:\n",
        "            print(\"No successful training batches!\")\n",
        "            break\n",
        "\n",
        "        avg_train_loss = train_loss / train_batches\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_batches = 0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                windows = batch['window'].to(device)\n",
        "                labels = batch['label'].to(device).float()\n",
        "\n",
        "                try:\n",
        "                    logits = model(windows)\n",
        "                    loss = criterion(logits, labels)\n",
        "\n",
        "                    val_loss += loss.item()\n",
        "                    val_batches += 1\n",
        "\n",
        "                    # Calculate accuracy\n",
        "                    predictions = (torch.sigmoid(logits) > 0.5).float()\n",
        "                    val_correct += (predictions == labels).sum().item()\n",
        "                    val_total += labels.size(0)\n",
        "\n",
        "                except RuntimeError as e:\n",
        "                    print(f\"Error in validation batch: {e}\")\n",
        "                    continue\n",
        "\n",
        "        if val_batches == 0:\n",
        "            print(\"No successful validation batches!\")\n",
        "            break\n",
        "\n",
        "        avg_val_loss = val_loss / val_batches\n",
        "        val_accuracy = val_correct / val_total\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        # Learning rate scheduling\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}, \"\n",
        "              f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
        "\n",
        "        # Early stopping and best model saving\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), MODEL_PATH)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience * 2:  # More patience for complex model\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "    return train_losses, val_losses\n",
        "\n",
        "# compute percentage of false predicted labels\n",
        "def sequence_level_accuracy(labels, predictions):\n",
        "    \"\"\"Compute the accuracy of individual window predictions.\"\"\"\n",
        "    correct = 0\n",
        "    total = len(labels) # Total number of windows\n",
        "\n",
        "    # Ensure labels and predictions have the same length\n",
        "    if len(labels) != len(predictions):\n",
        "        print(\"Warning: Length of labels and predictions do not match.\")\n",
        "        # Adjust total to the minimum length if lengths differ\n",
        "        total = min(len(labels), len(predictions))\n",
        "        labels = labels[:total]\n",
        "        predictions = predictions[:total]\n",
        "\n",
        "\n",
        "    for pred, label in zip(predictions, labels):\n",
        "        # Now comparing individual predictions and labels\n",
        "        if pred == label:\n",
        "            correct += 1\n",
        "    return correct / total\n",
        "\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    \"\"\"Evaluate the sliding window model\"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "            windows = batch['window'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            logits = model(windows)\n",
        "            probabilities = torch.sigmoid(logits)\n",
        "            predictions = (probabilities > 0.5).long()\n",
        "\n",
        "            all_preds.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_probs.extend(probabilities.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=['No Signal', 'Signal']))\n",
        "\n",
        "    f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
        "    f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
        "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    seq_acc = sequence_level_accuracy(all_labels, all_preds)\n",
        "\n",
        "    print(f\"F1 Score (weighted): {f1_weighted:.4f}\")\n",
        "    print(f\"F1 Score (macro): {f1_macro:.4f}\")\n",
        "    print(f\"Matthews Correlation Coefficient: {mcc:.4f}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Sequence-level Accuracy: {seq_acc:.4f}\")\n",
        "\n",
        "    return all_preds, all_labels, all_probs\n",
        "\n",
        "def predict_sequence(model, sequence, window_size, device, threshold=0.5):\n",
        "    \"\"\"Predict signal peptide positions for a full sequence\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Create dummy labels (we don't need them for prediction)\n",
        "    dummy_labels = [0] * len(sequence)\n",
        "\n",
        "    # Create sliding windows\n",
        "    windows, _, positions = create_sliding_windows(sequence, dummy_labels, window_size, stride=1)\n",
        "\n",
        "    # Encode windows\n",
        "    encoded_windows = get_protbert_window_embeddings(windows)\n",
        "\n",
        "    predictions = []\n",
        "    probabilities = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for encoded_window in encoded_windows:\n",
        "            window_tensor = torch.tensor(encoded_window, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "            logit = model(window_tensor)\n",
        "            prob = torch.sigmoid(logit).item()\n",
        "            pred = int(prob > threshold)\n",
        "\n",
        "            predictions.append(pred)\n",
        "            probabilities.append(prob)\n",
        "\n",
        "    return predictions, probabilities, positions\n",
        "\n",
        "# Load and preprocess data with sliding windows\n",
        "# This will create windows and labels but NOT encode them yet\n",
        "windows, labels, seq_ids, df_balanced = load_and_preprocess_data(FASTA_PATH)\n",
        "\n",
        "# --- Step 1: Pre-encode and Save Embeddings ---\n",
        "print(\"Encoding all windows...\")\n",
        "# Process windows in batches and save directly to disk\n",
        "embeddings_path = os.path.join(DRIVE_PATH, \"all_window_embeddings.npy\")\n",
        "labels_path = os.path.join(DRIVE_PATH, \"all_window_labels.npy\")\n",
        "df_balanced_path = os.path.join(DRIVE_PATH, \"df_balanced.csv\") # Save the balanced dataframe for later use if needed\n",
        "\n",
        "# Assuming the first window's embedding size will be consistent\n",
        "dummy_encoding = get_protbert_window_embeddings([windows[0]])\n",
        "embedding_dim = dummy_encoding.shape[-1]\n",
        "del dummy_encoding # Free up memory\n",
        "\n",
        "# Use the modified function to save embeddings incrementally\n",
        "all_embeddings = get_protbert_window_embeddings(\n",
        "    windows,\n",
        "    batch_size=BATCH_SIZE, # Use same batch size as for training/inference\n",
        "    output_path=embeddings_path,\n",
        "    embedding_dim=embedding_dim\n",
        ")\n",
        "\n",
        "# Save labels and balanced dataframe\n",
        "np.save(labels_path, np.array(labels))\n",
        "df_balanced.to_csv(df_balanced_path, index=False)\n",
        "\n",
        "print(f\"Embeddings saved to {embeddings_path}\")\n",
        "print(f\"Labels saved to {labels_path}\")\n",
        "print(f\"Balanced DataFrame saved to {df_balanced_path}\")\n",
        "\n",
        "# --- Step 2 & 3: Create Dataset instances using LazySlidingWindowDataset and Update Training/Evaluation ---\n",
        "\n",
        "# Split indices based on unique sequence IDs to avoid data leakage\n",
        "unique_seq_ids = list(df_balanced.index.unique()) # Use index from df_balanced\n",
        "train_seq_ids, temp_seq_ids = train_test_split(unique_seq_ids, test_size=0.2, random_state=42)\n",
        "val_seq_ids, test_seq_ids = train_test_split(temp_seq_ids, test_size=0.5, random_state=42) # 0.5 of 0.2 = 0.1 test size\n",
        "\n",
        "# Get indices corresponding to each split based on the original df_balanced index\n",
        "train_indices = [i for i, seq_id in enumerate(seq_ids) if seq_id in train_seq_ids]\n",
        "val_indices = [i for i, seq_id in enumerate(seq_ids) if seq_id in val_seq_ids]\n",
        "test_indices = [i for i, seq_id in enumerate(seq_ids) if seq_id in test_seq_ids]\n",
        "\n",
        "print(f\"\\nTrain windows (indices): {len(train_indices)}\")\n",
        "print(f\"Validation windows (indices): {len(val_indices)}\")\n",
        "print(f\"Test windows (indices): {len(test_indices)}\")\n",
        "\n",
        "# Create datasets and loaders using the saved files and indices\n",
        "train_dataset = LazySlidingWindowDataset(embeddings_path, labels_path, train_indices)\n",
        "val_dataset = LazySlidingWindowDataset(embeddings_path, labels_path, val_indices)\n",
        "test_dataset = LazySlidingWindowDataset(embeddings_path, labels_path, test_indices)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Initialize model (CNN version)\n",
        "# Use the embedding dimension determined from the dummy encoding\n",
        "model = CNNLSTMSignalPeptideClassifier(\n",
        "    WINDOW_SIZE, embedding_dim, hidden_dim=128, num_layers=2\n",
        ").to(DEVICE)\n",
        "\n",
        "print(f\"\\nModel parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "# Train model\n",
        "train_losses, val_losses = train_model(model, train_loader, val_loader, EPOCHS, DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2HkL4M0u-65x",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        },
        "id": "2HkL4M0u-65x",
        "outputId": "8d9870ed-5c35-42b3-9b64-987c9e64d9e5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score, matthews_corrcoef, accuracy_score\n",
        "from sklearn.utils import resample\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "DEVICE = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MODEL_NAME = \"Rostlab/prot_bert\"\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# Hyperparameters\n",
        "NUM_CLASSES = 2  # Binary classification (0: no signal peptide, 1: signal peptide)\n",
        "MAX_LENGTH = 70 # max sequence has len 70 in unpartitioned dataset\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "LR = 0.001\n",
        "WINDOW_SIZE = 35  # sliding window (odd because model predicts center residue)\n",
        "STRIDE = 1  # Step size for sliding window\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/PBLRost/\"\n",
        "FASTA_PATH = os.path.join(DRIVE_PATH, \"data/complete_set_unpartitioned.fasta\")\n",
        "MODEL_PATH = os.path.join(DRIVE_PATH, \"models/2state_tran_lin_cnn.pt\")\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME, do_lower_case=False)\n",
        "encoder = BertModel.from_pretrained(MODEL_NAME)\n",
        "encoder.to(DEVICE)\n",
        "\n",
        "def create_sliding_windows(sequence, labels, window_size, stride=1):\n",
        "    \"\"\"Create sliding windows from sequence and corresponding labels\"\"\"\n",
        "    windows = []\n",
        "    window_labels = []\n",
        "    positions = []\n",
        "\n",
        "    # Pad sequence for edge cases\n",
        "    pad_size = window_size // 2 # so starts classification after padding, at first real encoding\n",
        "    padded_seq = 'X' * pad_size + sequence + 'X' * pad_size\n",
        "    padded_labels = [0] * pad_size + labels + [0] * pad_size\n",
        "\n",
        "    # Create sliding windows\n",
        "    for i in range(0, len(sequence), stride):\n",
        "        start_idx = i\n",
        "        end_idx = i + window_size\n",
        "\n",
        "        if end_idx <= len(padded_seq):\n",
        "            window_seq = padded_seq[start_idx:end_idx]\n",
        "            # Label for the center position of the window\n",
        "            center_idx = start_idx + pad_size # residue to predict\n",
        "            if center_idx < len(padded_labels):\n",
        "                center_label = padded_labels[center_idx]\n",
        "\n",
        "                windows.append(window_seq)\n",
        "                window_labels.append(center_label)\n",
        "                positions.append(i)  # Original position in sequence\n",
        "\n",
        "    return windows, window_labels, positions\n",
        "\n",
        "def load_and_preprocess_data(fasta_path):\n",
        "    \"\"\"Load FASTA data and preprocess for sliding window approach\"\"\"\n",
        "    records = []\n",
        "\n",
        "    with open(fasta_path, \"r\") as f:\n",
        "        current_record = None\n",
        "        for line in f:\n",
        "            if line.startswith(\">\"):\n",
        "                if current_record is not None:\n",
        "                    if current_record[\"sequence\"] is not None and current_record[\"label\"] is not None:\n",
        "                        records.append(current_record)\n",
        "\n",
        "                uniprot_ac, kingdom, type_ = line[1:].strip().split(\"|\")\n",
        "                current_record = {\n",
        "                    \"uniprot_ac\": uniprot_ac,\n",
        "                    \"kingdom\": kingdom,\n",
        "                    \"type\": type_,\n",
        "                    \"sequence\": None,\n",
        "                    \"label\": None\n",
        "                }\n",
        "            else:\n",
        "                if current_record[\"sequence\"] is None:\n",
        "                    current_record[\"sequence\"] = line.strip()\n",
        "                elif current_record[\"label\"] is None:\n",
        "                    current_record[\"label\"] = line.strip()\n",
        "\n",
        "        # Add last record\n",
        "        if current_record is not None:\n",
        "            if current_record[\"sequence\"] is not None and current_record[\"label\"] is not None:\n",
        "                records.append(current_record)\n",
        "\n",
        "    print(f\"Total records loaded: {len(records)}\")\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df_raw = pd.DataFrame(records)\n",
        "\n",
        "    # Filter out sequences with 'P' in labels (if needed)\n",
        "    df = df_raw[~df_raw[\"label\"].str.contains(\"P\")]\n",
        "\n",
        "    # Map signal peptide types to binary classification\n",
        "    df[\"has_signal_peptide\"] = df[\"type\"].map({\n",
        "        \"NO_SP\": 0,\n",
        "        \"LIPO\": 1,\n",
        "        \"SP\": 1,\n",
        "        \"TAT\": 1,\n",
        "        \"TATLIPO\": 1\n",
        "    })\n",
        "\n",
        "    # Balance the dataset at sequence level first\n",
        "    df_majority = df[df[\"has_signal_peptide\"] == 0]\n",
        "    df_minority = df[df[\"has_signal_peptide\"] == 1]\n",
        "\n",
        "    if not df_minority.empty and not df_majority.empty:\n",
        "\n",
        "        n_samples = min(len(df_majority), 5000) # Limit samples to 5000 to prevent high ram usage\n",
        "        df_majority_sampled = resample(\n",
        "            df_majority,\n",
        "            replace=False, # sample without replacement\n",
        "            n_samples=n_samples,\n",
        "            random_state=42\n",
        "        )\n",
        "        df_balanced = pd.concat([df_majority_sampled, df_minority]) # Include all minority samples\n",
        "    else:\n",
        "        df_balanced = df.copy()\n",
        "\n",
        "\n",
        "    # Convert residue-level labels to binary\n",
        "    label_map = {'S': 1, 'T': 1, 'L': 1, 'I': 0, 'M': 0, 'O': 0}\n",
        "\n",
        "    # Create sliding windows for all sequences\n",
        "    all_windows = []\n",
        "    all_labels = []\n",
        "    all_seq_ids = []\n",
        "\n",
        "    for idx, row in df_balanced.iterrows():\n",
        "        sequence = row[\"sequence\"]\n",
        "        label_string = row[\"label\"]\n",
        "\n",
        "        # Convert label string to binary array\n",
        "        residue_labels = [label_map.get(c, 0) for c in label_string]\n",
        "\n",
        "        # Skip sequences where label length doesn't match sequence length\n",
        "        if len(residue_labels) != len(sequence):\n",
        "            print(\"A sequence length is not equal to the label length\")\n",
        "            continue\n",
        "\n",
        "        # Create sliding windows for this sequence\n",
        "        windows, window_labels, positions = create_sliding_windows(\n",
        "            sequence, residue_labels, WINDOW_SIZE, STRIDE\n",
        "        )\n",
        "\n",
        "        all_windows.extend(windows)\n",
        "        all_labels.extend(window_labels)\n",
        "        all_seq_ids.extend([idx] * len(windows))\n",
        "\n",
        "    print(f\"Total windows created: {len(all_windows)}\")\n",
        "    print(f\"Signal peptide windows: {sum(all_labels)}\")\n",
        "    print(f\"Non-signal peptide windows: {len(all_labels) - sum(all_labels)}\")\n",
        "\n",
        "    return all_windows, all_labels, all_seq_ids, df_balanced\n",
        "\n",
        "def get_protbert_window_embeddings(windows, batch_size=16, output_path=None, embedding_dim=1024):\n",
        "    \"\"\"\n",
        "    Output shape: (num_windows, window_size, embedding_dim)\n",
        "    If output_path is provided, saves embeddings to a memory-mapped file.\n",
        "    Otherwise, returns a concatenated NumPy array.\n",
        "    \"\"\"\n",
        "    formatted = [\" \".join(list(window)) for window in windows] # needed for tokenization\n",
        "    num_windows = len(formatted)\n",
        "    window_size = len(windows[0]) # Assuming all windows have the same size after padding/truncation\n",
        "\n",
        "    if output_path:\n",
        "        # Initialize memory-mapped array\n",
        "        # Need to estimate the exact sequence length after tokenization and potential padding/truncation\n",
        "        # A safer approach is to determine the max length after tokenization or use the known MAX_LENGTH\n",
        "        # Let's use MAX_LENGTH here, assuming it's the effective sequence length after tokenization and padding\n",
        "        print(f\"Initializing memory-mapped file at {output_path} with shape ({num_windows}, {MAX_LENGTH}, {embedding_dim})\")\n",
        "        all_embeddings_mmap = np.memmap(output_path, dtype='float32', mode='w+', shape=(num_windows, MAX_LENGTH, embedding_dim))\n",
        "\n",
        "    all_embeddings_list = [] # Keep this for the case where output_path is None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, num_windows, batch_size)):\n",
        "            batch_seqs = formatted[i:i+batch_size]\n",
        "            encoded = tokenizer(batch_seqs, return_tensors=\"pt\", padding=True, truncation=True, max_length=MAX_LENGTH)\n",
        "\n",
        "            input_ids = encoded['input_ids'].to(DEVICE)\n",
        "            attention_mask = encoded['attention_mask'].to(DEVICE)\n",
        "\n",
        "            outputs = encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            batch_embeddings = outputs.last_hidden_state.cpu().numpy() # (batch, seq_len, emb_dim)\n",
        "\n",
        "            # prot_bert adds [CLS] and [SEP]. We need to slice to get the actual window embeddings\n",
        "            # The actual sequence length before padding can vary within a batch due to truncation\n",
        "            # and the original un-padded window length.\n",
        "            # However, for consistent window embeddings of size MAX_LENGTH, we can just slice\n",
        "            # from index 1 up to MAX_LENGTH + 1 (to exclude CLS and include MAX_LENGTH tokens).\n",
        "            # If padding is present, the embeddings for padding tokens will be there but won't affect\n",
        "            # the actual sequence residues.\n",
        "            processed_batch_embeddings = batch_embeddings[:, 1:MAX_LENGTH+1, :] # Remove [CLS] token embedding\n",
        "\n",
        "            if output_path:\n",
        "                # Write directly to the memory-mapped array\n",
        "                end_idx = min(i + batch_size, num_windows)\n",
        "                all_embeddings_mmap[i:end_idx] = processed_batch_embeddings[:end_idx-i] # Handle the last batch size\n",
        "\n",
        "            else:\n",
        "                # Append to the list if not saving to file\n",
        "                for emb in processed_batch_embeddings:\n",
        "                    all_embeddings_list.append(emb)\n",
        "\n",
        "    if output_path:\n",
        "        # Ensure all changes are written to disk\n",
        "        all_embeddings_mmap.flush()\n",
        "        # The memory-mapped file will be returned. It behaves like a numpy array.\n",
        "        return all_embeddings_mmap\n",
        "    else:\n",
        "        # Return concatenated array\n",
        "        return np.stack(all_embeddings_list)\n",
        "\n",
        "class LazySlidingWindowDataset(Dataset):\n",
        "    def __init__(self, embeddings_path, labels_path, indices):\n",
        "        self.embeddings_path = embeddings_path\n",
        "        self.labels_path = labels_path\n",
        "        self.indices = indices # Indices corresponding to the split (train, val, or test)\n",
        "\n",
        "        # Load the full embeddings and labels once\n",
        "        self.all_embeddings = np.load(self.embeddings_path, mmap_mode='r') # Use mmap_mode to avoid loading everything into memory\n",
        "        self.all_labels = np.load(self.labels_path, mmap_mode='r')\n",
        "\n",
        "        # Ensure indices are within bounds (should be handled by splitting logic, but good practice)\n",
        "        if max(indices) >= len(self.all_labels) or min(indices) < 0:\n",
        "             raise ValueError(\"Indices are out of bounds for the loaded data.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the index in the original full dataset\n",
        "        original_idx = self.indices[idx]\n",
        "\n",
        "        # Load the specific embedding and label using the original index\n",
        "        # Slicing with numpy arrays loaded via mmap_mode='r' is efficient\n",
        "        embedding = self.all_embeddings[original_idx]\n",
        "        label = self.all_labels[original_idx]\n",
        "\n",
        "        return {\n",
        "            'window': torch.tensor(embedding, dtype=torch.float32),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "class CNNLSTMSignalPeptideClassifier(nn.Module):\n",
        "    def __init__(self, window_size, num_aa, hidden_dim=128, num_layers=2,\n",
        "                 cnn_channels=[64, 32], lstm_hidden=64, lstm_layers=2,\n",
        "                 use_bidirectional=True, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.window_size = window_size\n",
        "        self.num_aa = num_aa\n",
        "        self.use_bidirectional = use_bidirectional\n",
        "        self.lstm_hidden = lstm_hidden\n",
        "        self.lstm_layers = lstm_layers\n",
        "\n",
        "        # CNN layers for local pattern detection\n",
        "        self.conv_layers = nn.ModuleList()\n",
        "        in_channels = num_aa\n",
        "\n",
        "        for out_channels in cnn_channels:\n",
        "            self.conv_layers.append(nn.Sequential(\n",
        "                nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm1d(out_channels),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout)\n",
        "            ))\n",
        "            in_channels = out_channels\n",
        "\n",
        "        # LSTM layers for sequential dependencies\n",
        "        # Input to LSTM: [batch_size, seq_len, features]\n",
        "        lstm_input_size = cnn_channels[-1]  # Last CNN output channels\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=lstm_input_size,\n",
        "            hidden_size=lstm_hidden,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if lstm_layers > 1 else 0,\n",
        "            bidirectional=use_bidirectional\n",
        "        )\n",
        "\n",
        "        # Calculate LSTM output size\n",
        "        lstm_output_size = lstm_hidden * (2 if use_bidirectional else 1)\n",
        "\n",
        "        # Attention mechanism to focus on important positions\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(lstm_output_size, lstm_output_size // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(lstm_output_size // 2, 1)\n",
        "        )\n",
        "\n",
        "        # Final classification layers\n",
        "        classifier_layers = []\n",
        "        in_dim = lstm_output_size\n",
        "\n",
        "        for _ in range(num_layers):\n",
        "            classifier_layers.extend([\n",
        "                nn.Linear(in_dim, hidden_dim),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout)\n",
        "            ])\n",
        "            in_dim = hidden_dim\n",
        "\n",
        "        # Binary classification output\n",
        "        classifier_layers.append(nn.Linear(hidden_dim, 1))\n",
        "        self.classifier = nn.Sequential(*classifier_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, window_size, num_aa]\n",
        "        batch_size, seq_len, num_features = x.size()\n",
        "\n",
        "        # need [batch_size, num_aa, window_size] for Conv1d\n",
        "        x = x.transpose(1, 2)  # [batch_size, num_aa, window_size]\n",
        "\n",
        "        # Apply CNN layers\n",
        "        for conv_layer in self.conv_layers:\n",
        "            x = conv_layer(x)\n",
        "\n",
        "        # need [batch_size, seq_len, features] for LSTM\n",
        "        x = x.transpose(1, 2)  # [batch_size, window_size, cnn_channels[-1]]\n",
        "\n",
        "        # LSTM processing\n",
        "        lstm_out, (hidden, cell) = self.lstm(x)\n",
        "        # lstm_out: [batch_size, seq_len, lstm_hidden * directions]\n",
        "\n",
        "        # Apply attention mechanism\n",
        "        attention_weights = self.attention(lstm_out)  # [batch_size, seq_len, 1]\n",
        "        attention_weights = F.softmax(attention_weights, dim=1)\n",
        "\n",
        "        # Weighted sum of LSTM outputs\n",
        "        attended_output = torch.sum(lstm_out * attention_weights, dim=1)\n",
        "        # attended_output: [batch_size, lstm_hidden * directions]\n",
        "\n",
        "        # Final classification\n",
        "        logits = self.classifier(attended_output)\n",
        "        return logits.squeeze(-1)  # Remove last dimension\n",
        "\n",
        "\n",
        "class CNNLSTMSignalPeptideClassifierV2(nn.Module):\n",
        "    \"\"\"Alternative version with different CNN-LSTM integration\"\"\"\n",
        "    def __init__(self, window_size, num_aa, hidden_dim=128, num_layers=2,\n",
        "                 cnn_channels=[64, 32], lstm_hidden=64, lstm_layers=1,\n",
        "                 use_bidirectional=True, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.window_size = window_size\n",
        "        self.num_aa = num_aa\n",
        "\n",
        "        # CNN feature extractor\n",
        "        self.cnn_backbone = nn.Sequential(\n",
        "            # First conv block\n",
        "            nn.Conv1d(num_aa, cnn_channels[0], kernel_size=5, padding=2),\n",
        "            nn.BatchNorm1d(cnn_channels[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            # Second conv block\n",
        "            nn.Conv1d(cnn_channels[0], cnn_channels[1], kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(cnn_channels[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            # Third conv block\n",
        "            nn.Conv1d(cnn_channels[1], cnn_channels[1], kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(cnn_channels[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        # LSTM for sequential modeling\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=cnn_channels[-1],\n",
        "            hidden_size=lstm_hidden,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if lstm_layers > 1 else 0,\n",
        "            bidirectional=use_bidirectional\n",
        "        )\n",
        "\n",
        "        # Calculate dimensions\n",
        "        lstm_output_size = lstm_hidden * (2 if use_bidirectional else 1)\n",
        "\n",
        "        # Global pooling options\n",
        "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
        "\n",
        "        # Classification head\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(lstm_output_size, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim // 2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, window_size, num_aa]\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # CNN feature extraction\n",
        "        x = x.transpose(1, 2)  # [batch_size, num_aa, window_size]\n",
        "        cnn_features = self.cnn_backbone(x)\n",
        "\n",
        "        # Prepare for LSTM\n",
        "        x = cnn_features.transpose(1, 2)  # [batch_size, window_size, features]\n",
        "\n",
        "        # LSTM processing\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "\n",
        "        # Global pooling over sequence dimension\n",
        "        lstm_out = lstm_out.transpose(1, 2)  # [batch_size, features, seq_len]\n",
        "        pooled = self.global_pool(lstm_out).squeeze(-1)  # [batch_size, features]\n",
        "\n",
        "        # Classification\n",
        "        logits = self.classifier(pooled)\n",
        "        return logits.squeeze(-1)\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs, device,\n",
        "                        lr=0.001, weight_decay=1e-5, patience=5):\n",
        "    \"\"\"Enhanced training function with gradient clipping and better scheduling\"\"\"\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # More sophisticated learning rate scheduling\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', patience=patience, factor=0.5, verbose=True\n",
        "    )\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_batches = 0\n",
        "\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        for batch in progress_bar:\n",
        "            windows = batch['window'].to(device)\n",
        "            labels = batch['label'].to(device).float()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            try:\n",
        "                logits = model(windows)\n",
        "                loss = criterion(logits, labels)\n",
        "\n",
        "                loss.backward()\n",
        "\n",
        "                # Gradient clipping to prevent exploding gradients\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item()\n",
        "                train_batches += 1\n",
        "\n",
        "                progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                print(f\"Error in training batch: {e}\")\n",
        "                continue\n",
        "\n",
        "        if train_batches == 0:\n",
        "            print(\"No successful training batches!\")\n",
        "            break\n",
        "\n",
        "        avg_train_loss = train_loss / train_batches\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_batches = 0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                windows = batch['window'].to(device)\n",
        "                labels = batch['label'].to(device).float()\n",
        "\n",
        "                try:\n",
        "                    logits = model(windows)\n",
        "                    loss = criterion(logits, labels)\n",
        "\n",
        "                    val_loss += loss.item()\n",
        "                    val_batches += 1\n",
        "\n",
        "                    # Calculate accuracy\n",
        "                    predictions = (torch.sigmoid(logits) > 0.5).float()\n",
        "                    val_correct += (predictions == labels).sum().item()\n",
        "                    val_total += labels.size(0)\n",
        "\n",
        "                except RuntimeError as e:\n",
        "                    print(f\"Error in validation batch: {e}\")\n",
        "                    continue\n",
        "\n",
        "        if val_batches == 0:\n",
        "            print(\"No successful validation batches!\")\n",
        "            break\n",
        "\n",
        "        avg_val_loss = val_loss / val_batches\n",
        "        val_accuracy = val_correct / val_total\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        # Learning rate scheduling\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}, \"\n",
        "              f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
        "\n",
        "        # Early stopping and best model saving\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), MODEL_PATH)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience * 2:  # More patience for complex model\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "    return train_losses, val_losses\n",
        "\n",
        "# compute percentage of false predicted labels\n",
        "def sequence_level_accuracy(labels, predictions):\n",
        "    \"\"\"Compute the accuracy of individual window predictions.\"\"\"\n",
        "    correct = 0\n",
        "    total = len(labels) # Total number of windows\n",
        "\n",
        "    # Ensure labels and predictions have the same length\n",
        "    if len(labels) != len(predictions):\n",
        "        print(\"Warning: Length of labels and predictions do not match.\")\n",
        "        # Adjust total to the minimum length if lengths differ\n",
        "        total = min(len(labels), len(predictions))\n",
        "        labels = labels[:total]\n",
        "        predictions = predictions[:total]\n",
        "\n",
        "\n",
        "    for pred, label in zip(predictions, labels):\n",
        "        # Now comparing individual predictions and labels\n",
        "        if pred == label:\n",
        "            correct += 1\n",
        "    return correct / total\n",
        "\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    \"\"\"Evaluate the sliding window model\"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "            windows = batch['window'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            logits = model(windows)\n",
        "            probabilities = torch.sigmoid(logits)\n",
        "            predictions = (probabilities > 0.5).long()\n",
        "\n",
        "            all_preds.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_probs.extend(probabilities.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=['No Signal', 'Signal']))\n",
        "\n",
        "    f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
        "    f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
        "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    seq_acc = sequence_level_accuracy(all_labels, all_preds)\n",
        "\n",
        "    print(f\"F1 Score (weighted): {f1_weighted:.4f}\")\n",
        "    print(f\"F1 Score (macro): {f1_macro:.4f}\")\n",
        "    print(f\"Matthews Correlation Coefficient: {mcc:.4f}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Sequence-level Accuracy: {seq_acc:.4f}\")\n",
        "\n",
        "    return all_preds, all_labels, all_probs\n",
        "\n",
        "def predict_sequence(model, sequence, window_size, device, threshold=0.5):\n",
        "    \"\"\"Predict signal peptide positions for a full sequence\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Create dummy labels (we don't need them for prediction)\n",
        "    dummy_labels = [0] * len(sequence)\n",
        "\n",
        "    # Create sliding windows\n",
        "    windows, _, positions = create_sliding_windows(sequence, dummy_labels, window_size, stride=1)\n",
        "\n",
        "    # Encode windows\n",
        "    encoded_windows = get_protbert_window_embeddings(windows)\n",
        "\n",
        "    predictions = []\n",
        "    probabilities = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for encoded_window in encoded_windows:\n",
        "            window_tensor = torch.tensor(encoded_window, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "            logit = model(window_tensor)\n",
        "            prob = torch.sigmoid(logit).item()\n",
        "            pred = int(prob > threshold)\n",
        "\n",
        "            predictions.append(pred)\n",
        "            probabilities.append(prob)\n",
        "\n",
        "    return predictions, probabilities, positions\n",
        "\n",
        "# Load and preprocess data with sliding windows\n",
        "# This will create windows and labels but NOT encode them yet\n",
        "windows, labels, seq_ids, df_balanced = load_and_preprocess_data(FASTA_PATH)\n",
        "\n",
        "# --- Step 1: Pre-encode and Save Embeddings ---\n",
        "print(\"Encoding all windows...\")\n",
        "# Process windows in batches and save directly to disk\n",
        "embeddings_path = os.path.join(DRIVE_PATH, \"all_window_embeddings.npy\")\n",
        "labels_path = os.path.join(DRIVE_PATH, \"all_window_labels.npy\")\n",
        "df_balanced_path = os.path.join(DRIVE_PATH, \"df_balanced.csv\") # Save the balanced dataframe for later use if needed\n",
        "\n",
        "# Assuming the first window's embedding size will be consistent\n",
        "dummy_encoding = get_protbert_window_embeddings([windows[0]])\n",
        "embedding_dim = dummy_encoding.shape[-1]\n",
        "del dummy_encoding # Free up memory\n",
        "\n",
        "# Use the modified function to save embeddings incrementally\n",
        "all_embeddings = get_protbert_window_embeddings(\n",
        "    windows,\n",
        "    batch_size=BATCH_SIZE, # Use same batch size as for training/inference\n",
        "    output_path=embeddings_path,\n",
        "    embedding_dim=embedding_dim\n",
        ")\n",
        "\n",
        "# Save labels and balanced dataframe\n",
        "np.save(labels_path, np.array(labels))\n",
        "df_balanced.to_csv(df_balanced_path, index=False)\n",
        "\n",
        "print(f\"Embeddings saved to {embeddings_path}\")\n",
        "print(f\"Labels saved to {labels_path}\")\n",
        "print(f\"Balanced DataFrame saved to {df_balanced_path}\")\n",
        "\n",
        "# --- Step 2 & 3: Create Dataset instances using LazySlidingWindowDataset and Update Training/Evaluation ---\n",
        "\n",
        "# Split indices based on unique sequence IDs to avoid data leakage\n",
        "unique_seq_ids = list(df_balanced.index.unique()) # Use index from df_balanced\n",
        "train_seq_ids, temp_seq_ids = train_test_split(unique_seq_ids, test_size=0.2, random_state=42)\n",
        "val_seq_ids, test_seq_ids = train_test_split(temp_seq_ids, test_size=0.5, random_state=42) # 0.5 of 0.2 = 0.1 test size\n",
        "\n",
        "# Get indices corresponding to each split based on the original df_balanced index\n",
        "train_indices = [i for i, seq_id in enumerate(seq_ids) if seq_id in train_seq_ids]\n",
        "val_indices = [i for i, seq_id in enumerate(seq_ids) if seq_id in val_seq_ids]\n",
        "test_indices = [i for i, seq_id in enumerate(seq_ids) if seq_id in test_seq_ids]\n",
        "\n",
        "print(f\"\\nTrain windows (indices): {len(train_indices)}\")\n",
        "print(f\"Validation windows (indices): {len(val_indices)}\")\n",
        "print(f\"Test windows (indices): {len(test_indices)}\")\n",
        "\n",
        "# Create datasets and loaders using the saved files and indices\n",
        "train_dataset = LazySlidingWindowDataset(embeddings_path, labels_path, train_indices)\n",
        "val_dataset = LazySlidingWindowDataset(embeddings_path, labels_path, val_indices)\n",
        "test_dataset = LazySlidingWindowDataset(embeddings_path, labels_path, test_indices)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Initialize model (CNN version)\n",
        "# Use the embedding dimension determined from the dummy encoding\n",
        "model = CNNLSTMSignalPeptideClassifier(\n",
        "    WINDOW_SIZE, embedding_dim, hidden_dim=128, num_layers=2\n",
        ").to(DEVICE)\n",
        "\n",
        "print(f\"\\nModel parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "# Train model\n",
        "train_losses, val_losses = train_model(model, train_loader, val_loader, EPOCHS, DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f70f4bf",
      "metadata": {
        "id": "5f70f4bf"
      },
      "source": [
        "**Reasoning**:\n",
        "The `ValueError: could not broadcast input array from shape (32,36,1024) into shape (32,70,1024)` indicates that the shape of the processed batch embeddings (`processed_batch_embeddings`) is (batch_size, 36, 1024), but the memory-mapped array `all_embeddings_mmap` was initialized with a shape that implies a sequence length of 70 (`(num_windows, MAX_LENGTH, embedding_dim)` where `MAX_LENGTH` is 70). The discrepancy (36 vs 70) comes from how the sequence length is handled after tokenization and slicing within the `get_protbert_window_embeddings` function. The slice `batch_embeddings[:, 1:MAX_LENGTH+1, :]` should align with the expected window size after tokenization, which seems to be 35 (WINDOW_SIZE) plus the [SEP] token, resulting in 36. The memory-mapped file shape should be based on this actual resulting dimension, not `MAX_LENGTH`.\n",
        "\n",
        "To fix this, the shape of the memory-mapped array `all_embeddings_mmap` should be initialized using the actual sequence length of the processed embeddings (36 in this case, which corresponds to `WINDOW_SIZE + 1` for the [SEP] token after removing [CLS]), instead of `MAX_LENGTH`. I will remove the dummy encoding call to get the embedding dimension, as the transformer model always outputs embeddings of a fixed size (1024 for ProtBert). The sequence length dimension for the memory-mapped array should be determined by the actual size of `processed_batch_embeddings` after slicing `[:, 1:MAX_LENGTH+1, :]`. However, this slicing is intended to get the embeddings for the `MAX_LENGTH` window. The issue is that the tokenizer output shape is determined by `MAX_LENGTH`, and slicing `[:, 1:MAX_LENGTH+1, :]` should result in a sequence length of `MAX_LENGTH`.\n",
        "\n",
        "Let's re-examine the slicing logic. The tokenizer is called with `max_length=MAX_LENGTH` and `padding=True`. This means the tokenized sequence will have `MAX_LENGTH` tokens + [CLS] + [SEP], so `MAX_LENGTH + 2` total tokens, or `MAX_LENGTH + 1` if the original sequence fits exactly and `truncation=True` removes the last token, or just `MAX_LENGTH` if padding is needed. Given `MAX_LENGTH = 70` and `WINDOW_SIZE = 35`, the window length is 35. The tokenization adds [CLS] and [SEP]. A window of 35 AAs becomes `[CLS] A A ... A [SEP]` which is 37 tokens. Padding will extend this to `MAX_LENGTH + 2` tokens if the window is shorter than `MAX_LENGTH`. The slicing `[:, 1:MAX_LENGTH+1, :]` aims to remove the [CLS] token (index 0) and keep up to `MAX_LENGTH` tokens. This would result in a shape with sequence length `MAX_LENGTH`.\n",
        "\n",
        "The error suggests `processed_batch_embeddings` has a sequence length of 36. This implies the slicing `[:, 1:MAX_LENGTH+1, :]` is effectively doing `[:, 1:37, :]` when `MAX_LENGTH` is 70. This is unexpected. Let's assume the issue is in how the target sequence length is determined for the memory-mapped file. The target sequence length for a window embedding should be `MAX_LENGTH` as defined by the tokenizer/padding, or the actual length of the window + 2 if padding/truncation are not active. Given we use padding and truncation with `max_length=MAX_LENGTH`, the output sequence length from the encoder should conceptually be `MAX_LENGTH` (excluding special tokens if sliced correctly).\n",
        "\n",
        "The slicing `outputs.last_hidden_state[j, 1:seq_len+1, :]` in the original `get_protbert_window_embeddings` (before modification) intended to get the actual sequence length `seq_len` from the *original* window before tokenization/padding/truncation and then slice from index 1 (skipping CLS) up to `seq_len+1`. This would result in variable sequence lengths depending on the original window size.\n",
        "The modified function uses `processed_batch_embeddings = batch_embeddings[:, 1:MAX_LENGTH+1, :]`. This slice intends to get embeddings for a sequence length of `MAX_LENGTH`. The `ValueError` shows it got 36.\n",
        "\n",
        "Let's clarify the expected shape of the processed embeddings. A window of size `WINDOW_SIZE` (35) is tokenized with `max_length=MAX_LENGTH` (70) and `padding=True`, `truncation=True`. ProtBert adds [CLS] and [SEP]. The resulting token sequence will be `[CLS] A A ... A [SEP]` potentially padded or truncated to fit within `MAX_LENGTH`. If a 35 AA window is tokenized, it becomes `[CLS] AA1 AA2 ... AA35 [SEP]`. This is 37 tokens. With `max_length=70` and padding, this sequence would be padded up to 72 tokens (including [CLS] and [SEP]). `outputs.last_hidden_state` would have shape `(batch_size, 72, 1024)`. The slice `[:, 1:MAX_LENGTH+1, :]` i.e., `[:, 1:71, :]` would then result in shape `(batch_size, 70, 1024)`. This aligns with the intended `MAX_LENGTH`.\n",
        "\n",
        "The error shape (32, 36, 1024) is puzzling. It suggests the sequence length is 36 after slicing. This would happen if the slice was `[:, 1:37, :]`. Why would `MAX_LENGTH+1` result in 37 when `MAX_LENGTH` is 70?\n",
        "\n",
        "Let's rethink the slicing logic in `get_protbert_window_embeddings`. The goal is to get the embeddings corresponding to the `WINDOW_SIZE` amino acids of the input window. ProtBert tokenizes \"A A B B ...\" adding [CLS] and [SEP]. So a window of size `W` becomes `[CLS]` W tokens `[SEP]`. The embeddings from the encoder will have shape `(batch_size, W+2, emb_dim)`. If we pad/truncate to `MAX_LENGTH`, the shape becomes `(batch_size, MAX_LENGTH+2, emb_dim)`. We want the embeddings for the original `WINDOW_SIZE` residues. These correspond to indices 1 to `WINDOW_SIZE` in the tokenized sequence. So the slice should be `[:, 1:WINDOW_SIZE+1, :]`. This would give embeddings of shape `(batch_size, WINDOW_SIZE, emb_dim)`. The memory-mapped file should then have shape `(num_windows, WINDOW_SIZE, embedding_dim)`.\n",
        "\n",
        "Let's adjust the `get_protbert_window_embeddings` to slice based on `WINDOW_SIZE` and initialize the memory-mapped array shape based on `WINDOW_SIZE`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ULeFx7f_XAM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "id": "1ULeFx7f_XAM",
        "outputId": "598135fe-390b-4667-c201-cc8474ae8202"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score, matthews_corrcoef, accuracy_score\n",
        "from sklearn.utils import resample\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "DEVICE = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MODEL_NAME = \"Rostlab/prot_bert\"\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# Hyperparameters\n",
        "NUM_CLASSES = 2  # Binary classification (0: no signal peptide, 1: signal peptide)\n",
        "MAX_LENGTH = 70 # max sequence has len 70 in unpartitioned dataset\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "LR = 0.001\n",
        "WINDOW_SIZE = 35  # sliding window (odd because model predicts center residue)\n",
        "STRIDE = 1  # Step size for sliding window\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/PBLRost/\"\n",
        "FASTA_PATH = os.path.join(DRIVE_PATH, \"data/complete_set_unpartitioned.fasta\")\n",
        "MODEL_PATH = os.path.join(DRIVE_PATH, \"models/2state_tran_lin_cnn.pt\")\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME, do_lower_case=False)\n",
        "encoder = BertModel.from_pretrained(MODEL_NAME)\n",
        "encoder.to(DEVICE)\n",
        "\n",
        "def create_sliding_windows(sequence, labels, window_size, stride=1):\n",
        "    \"\"\"Create sliding windows from sequence and corresponding labels\"\"\"\n",
        "    windows = []\n",
        "    window_labels = []\n",
        "    positions = []\n",
        "\n",
        "    # Pad sequence for edge cases\n",
        "    pad_size = window_size // 2 # so starts classification after padding, at first real encoding\n",
        "    padded_seq = 'X' * pad_size + sequence + 'X' * pad_size\n",
        "    padded_labels = [0] * pad_size + labels + [0] * pad_size\n",
        "\n",
        "    # Create sliding windows\n",
        "    for i in range(0, len(sequence), stride):\n",
        "        start_idx = i\n",
        "        end_idx = i + window_size\n",
        "\n",
        "        if end_idx <= len(padded_seq):\n",
        "            window_seq = padded_seq[start_idx:end_idx]\n",
        "            # Label for the center position of the window\n",
        "            center_idx = start_idx + pad_size # residue to predict\n",
        "            if center_idx < len(padded_labels):\n",
        "                center_label = padded_labels[center_idx]\n",
        "\n",
        "                windows.append(window_seq)\n",
        "                window_labels.append(center_label)\n",
        "                positions.append(i)  # Original position in sequence\n",
        "\n",
        "    return windows, window_labels, positions\n",
        "\n",
        "def get_protbert_window_embeddings(windows, batch_size=16, output_path=None, embedding_dim=1024):\n",
        "    \"\"\"\n",
        "    Output shape: (num_windows, window_size, embedding_dim)\n",
        "    If output_path is provided, saves embeddings to a memory-mapped file.\n",
        "    Otherwise, returns a concatenated NumPy array.\n",
        "    Slices to get embeddings for the WINDOW_SIZE amino acids.\n",
        "    \"\"\"\n",
        "    formatted = [\" \".join(list(window)) for window in windows] # needed for tokenization\n",
        "    num_windows = len(formatted)\n",
        "\n",
        "    # The actual sequence length after tokenization and slicing will be WINDOW_SIZE\n",
        "    target_seq_length = WINDOW_SIZE\n",
        "\n",
        "    if output_path:\n",
        "        # Initialize memory-mapped array with the correct sequence length\n",
        "        print(f\"Initializing memory-mapped file at {output_path} with shape ({num_windows}, {target_seq_length}, {embedding_dim})\")\n",
        "        all_embeddings_mmap = np.memmap(output_path, dtype='float32', mode='w+', shape=(num_windows, target_seq_length, embedding_dim))\n",
        "\n",
        "    all_embeddings_list = [] # Keep this for the case where output_path is None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, num_windows, batch_size)):\n",
        "            batch_seqs = formatted[i:i+batch_size]\n",
        "            # Use MAX_LENGTH for tokenizer max_length to handle longer sequences,\n",
        "            # but we will slice to WINDOW_SIZE afterwards.\n",
        "            encoded = tokenizer(batch_seqs, return_tensors=\"pt\", padding=True, truncation=True, max_length=MAX_LENGTH)\n",
        "\n",
        "            input_ids = encoded['input_ids'].to(DEVICE)\n",
        "            attention_mask = encoded['attention_mask'].to(DEVICE)\n",
        "\n",
        "            outputs = encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            batch_embeddings = outputs.last_hidden_state.cpu().numpy() # (batch, tokenized_seq_len, emb_dim)\n",
        "\n",
        "            # Slice to get embeddings for the WINDOW_SIZE amino acids (excluding [CLS] and [SEP])\n",
        "            # These are typically at indices 1 to WINDOW_SIZE in the tokenized sequence if not padded/truncated.\n",
        "            # If padded/truncated, the first WINDOW_SIZE relevant tokens might be padded.\n",
        "            # We need to be careful here. The model expects a fixed size input WINDOW_SIZE.\n",
        "            # Let's assume the slicing should always result in WINDOW_SIZE.\n",
        "            # If the tokenized sequence is shorter than WINDOW_SIZE + 2 after truncation,\n",
        "            # this slice might be out of bounds or return fewer than WINDOW_SIZE embeddings.\n",
        "            # Given MAX_LENGTH is 70 and WINDOW_SIZE is 35, a 35 AA window tokenizes to 37 tokens ([CLS], 35 AA, [SEP]).\n",
        "            # With padding/truncation to MAX_LENGTH=70, the output tensor will be shape (batch, 72, 1024).\n",
        "            # We want the 35 AA embeddings, which are at indices 1 to 36.\n",
        "            # So the slice should be [:, 1:WINDOW_SIZE+1, :]\n",
        "            processed_batch_embeddings = batch_embeddings[:, 1:WINDOW_SIZE+1, :] # Shape (batch, WINDOW_SIZE, emb_dim)\n",
        "\n",
        "\n",
        "            if output_path:\n",
        "                # Write directly to the memory-mapped array\n",
        "                end_idx = min(i + batch_size, num_windows)\n",
        "                # Ensure the batch size written matches the actual batch size\n",
        "                batch_size_actual = processed_batch_embeddings.shape[0]\n",
        "                all_embeddings_mmap[i:i+batch_size_actual] = processed_batch_embeddings # Handle the last batch size\n",
        "\n",
        "            else:\n",
        "                # Append to the list if not saving to file\n",
        "                for emb in processed_batch_embeddings:\n",
        "                    all_embeddings_list.append(emb)\n",
        "\n",
        "    if output_path:\n",
        "        # Ensure all changes are written to disk\n",
        "        all_embeddings_mmap.flush()\n",
        "        # The memory-mapped file will be returned. It behaves like a numpy array.\n",
        "        return all_embeddings_mmap\n",
        "    else:\n",
        "        # Return concatenated array\n",
        "        return np.stack(all_embeddings_list)\n",
        "\n",
        "class LazySlidingWindowDataset(Dataset):\n",
        "    def __init__(self, embeddings_path, labels_path, indices):\n",
        "        self.embeddings_path = embeddings_path\n",
        "        self.labels_path = labels_path\n",
        "        self.indices = indices # Indices corresponding to the split (train, val, or test)\n",
        "\n",
        "        # Load the full embeddings and labels once\n",
        "        self.all_embeddings = np.load(self.embeddings_path, mmap_mode='r') # Use mmap_mode to avoid loading everything into memory\n",
        "        self.all_labels = np.load(self.labels_path, mmap_mode='r')\n",
        "\n",
        "        # Ensure indices are within bounds (should be handled by splitting logic, but good practice)\n",
        "        if max(indices) >= len(self.all_labels) or min(indices) < 0:\n",
        "             raise ValueError(\"Indices are out of bounds for the loaded data.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the index in the original full dataset\n",
        "        original_idx = self.indices[idx]\n",
        "\n",
        "        # Load the specific embedding and label using the original index\n",
        "        # Slicing with numpy arrays loaded via mmap_mode='r' is efficient\n",
        "        embedding = self.all_embeddings[original_idx]\n",
        "        label = self.all_labels[original_idx]\n",
        "\n",
        "        return {\n",
        "            'window': torch.tensor(embedding, dtype=torch.float32),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "class CNNLSTMSignalPeptideClassifier(nn.Module):\n",
        "    def __init__(self, window_size, num_aa, hidden_dim=128, num_layers=2,\n",
        "                 cnn_channels=[64, 32], lstm_hidden=64, lstm_layers=2,\n",
        "                 use_bidirectional=True, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.window_size = window_size\n",
        "        self.num_aa = num_aa\n",
        "        self.use_bidirectional = use_bidirectional\n",
        "        self.lstm_hidden = lstm_hidden\n",
        "        self.lstm_layers = lstm_layers\n",
        "\n",
        "        # CNN layers for local pattern detection\n",
        "        self.conv_layers = nn.ModuleList()\n",
        "        in_channels = num_aa\n",
        "\n",
        "        for out_channels in cnn_channels:\n",
        "            self.conv_layers.append(nn.Sequential(\n",
        "                nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm1d(out_channels),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout)\n",
        "            ))\n",
        "            in_channels = out_channels\n",
        "\n",
        "        # LSTM layers for sequential dependencies\n",
        "        # Input to LSTM: [batch_size, seq_len, features]\n",
        "        lstm_input_size = cnn_channels[-1]  # Last CNN output channels\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=lstm_input_size,\n",
        "            hidden_size=lstm_hidden,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if lstm_layers > 1 else 0,\n",
        "            bidirectional=use_bidirectional\n",
        "        )\n",
        "\n",
        "        # Calculate LSTM output size\n",
        "        lstm_output_size = lstm_hidden * (2 if use_bidirectional else 1)\n",
        "\n",
        "        # Attention mechanism to focus on important positions\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(lstm_output_size, lstm_output_size // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(lstm_output_size // 2, 1)\n",
        "        )\n",
        "\n",
        "        # Final classification layers\n",
        "        classifier_layers = []\n",
        "        in_dim = lstm_output_size\n",
        "\n",
        "        for _ in range(num_layers):\n",
        "            classifier_layers.extend([\n",
        "                nn.Linear(in_dim, hidden_dim),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout)\n",
        "            ])\n",
        "            in_dim = hidden_dim\n",
        "\n",
        "        # Binary classification output\n",
        "        classifier_layers.append(nn.Linear(hidden_dim, 1))\n",
        "        self.classifier = nn.Sequential(*classifier_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, window_size, num_aa]\n",
        "        batch_size, seq_len, num_features = x.size()\n",
        "\n",
        "        # need [batch_size, num_aa, window_size] for Conv1d\n",
        "        x = x.transpose(1, 2)  # [batch_size, num_aa, window_size]\n",
        "\n",
        "        # Apply CNN layers\n",
        "        for conv_layer in self.conv_layers:\n",
        "            x = conv_layer(x)\n",
        "\n",
        "        # need [batch_size, seq_len, features] for LSTM\n",
        "        x = x.transpose(1, 2)  # [batch_size, window_size, cnn_channels[-1]]\n",
        "\n",
        "        # LSTM processing\n",
        "        lstm_out, (hidden, cell) = self.lstm(x)\n",
        "        # lstm_out: [batch_size, seq_len, lstm_hidden * directions]\n",
        "\n",
        "        # Apply attention mechanism\n",
        "        attention_weights = self.attention(lstm_out)  # [batch_size, seq_len, 1]\n",
        "        attention_weights = F.softmax(attention_weights, dim=1)\n",
        "\n",
        "        # Weighted sum of LSTM outputs\n",
        "        attended_output = torch.sum(lstm_out * attention_weights, dim=1)\n",
        "        # attended_output: [batch_size, lstm_hidden * directions]\n",
        "\n",
        "        # Final classification\n",
        "        logits = self.classifier(attended_output)\n",
        "        return logits.squeeze(-1)  # Remove last dimension\n",
        "\n",
        "\n",
        "class CNNLSTMSignalPeptideClassifierV2(nn.Module):\n",
        "    \"\"\"Alternative version with different CNN-LSTM integration\"\"\"\n",
        "    def __init__(self, window_size, num_aa, hidden_dim=128, num_layers=2,\n",
        "                 cnn_channels=[64, 32], lstm_hidden=64, lstm_layers=1,\n",
        "                 use_bidirectional=True, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.window_size = window_size\n",
        "        self.num_aa = num_aa\n",
        "\n",
        "        # CNN feature extractor\n",
        "        self.cnn_backbone = nn.Sequential(\n",
        "            # First conv block\n",
        "            nn.Conv1d(num_aa, cnn_channels[0], kernel_size=5, padding=2),\n",
        "            nn.BatchNorm1d(cnn_channels[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            # Second conv block\n",
        "            nn.Conv1d(cnn_channels[0], cnn_channels[1], kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(cnn_channels[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            # Third conv block\n",
        "            nn.Conv1d(cnn_channels[1], cnn_channels[1], kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(cnn_channels[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        # LSTM for sequential modeling\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=cnn_channels[-1],\n",
        "            hidden_size=lstm_hidden,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if lstm_layers > 1 else 0,\n",
        "            bidirectional=use_bidirectional\n",
        "        )\n",
        "\n",
        "        # Calculate dimensions\n",
        "        lstm_output_size = lstm_hidden * (2 if use_bidirectional else 1)\n",
        "\n",
        "        # Global pooling options\n",
        "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
        "\n",
        "        # Classification head\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(lstm_output_size, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim // 2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, window_size, num_aa]\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # CNN feature extraction\n",
        "        x = x.transpose(1, 2)  # [batch_size, num_aa, window_size]\n",
        "        cnn_features = self.cnn_backbone(x)\n",
        "\n",
        "        # Prepare for LSTM\n",
        "        x = cnn_features.transpose(1, 2)  # [batch_size, window_size, features]\n",
        "\n",
        "        # LSTM processing\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "\n",
        "        # Global pooling over sequence dimension\n",
        "        lstm_out = lstm_out.transpose(1, 2)  # [batch_size, features, seq_len]\n",
        "        pooled = self.global_pool(lstm_out).squeeze(-1)  # [batch_size, features]\n",
        "\n",
        "        # Classification\n",
        "        logits = self.classifier(pooled)\n",
        "        return logits.squeeze(-1)\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs, device,\n",
        "                        lr=0.001, weight_decay=1e-5, patience=5):\n",
        "    \"\"\"Enhanced training function with gradient clipping and better scheduling\"\"\"\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # More sophisticated learning rate scheduling\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', patience=patience, factor=0.5, verbose=True\n",
        "    )\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_batches = 0\n",
        "\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        for batch in progress_bar:\n",
        "            windows = batch['window'].to(device)\n",
        "            labels = batch['label'].to(device).float()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            try:\n",
        "                logits = model(windows)\n",
        "                loss = criterion(logits, labels)\n",
        "\n",
        "                loss.backward()\n",
        "\n",
        "                # Gradient clipping to prevent exploding gradients\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item()\n",
        "                train_batches += 1\n",
        "\n",
        "                progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                print(f\"Error in training batch: {e}\")\n",
        "                continue\n",
        "\n",
        "        if train_batches == 0:\n",
        "            print(\"No successful training batches!\")\n",
        "            break\n",
        "\n",
        "        avg_train_loss = train_loss / train_batches\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_batches = 0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                windows = batch['window'].to(device)\n",
        "                labels = batch['label'].to(device).float()\n",
        "\n",
        "                try:\n",
        "                    logits = model(windows)\n",
        "                    loss = criterion(logits, labels)\n",
        "\n",
        "                    val_loss += loss.item()\n",
        "                    val_batches += 1\n",
        "\n",
        "                    # Calculate accuracy\n",
        "                    predictions = (torch.sigmoid(logits) > 0.5).float()\n",
        "                    val_correct += (predictions == labels).sum().item()\n",
        "                    val_total += labels.size(0)\n",
        "\n",
        "                except RuntimeError as e:\n",
        "                    print(f\"Error in validation batch: {e}\")\n",
        "                    continue\n",
        "\n",
        "        if val_batches == 0:\n",
        "            print(\"No successful validation batches!\")\n",
        "            break\n",
        "\n",
        "        avg_val_loss = val_loss / val_batches\n",
        "        val_accuracy = val_correct / val_total\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        # Learning rate scheduling\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}, \"\n",
        "              f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
        "\n",
        "        # Early stopping and best model saving\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), MODEL_PATH)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience * 2:  # More patience for complex model\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "    return train_losses, val_losses\n",
        "\n",
        "# compute percentage of false predicted labels\n",
        "def sequence_level_accuracy(labels, predictions):\n",
        "    \"\"\"Compute the accuracy of individual window predictions.\"\"\"\n",
        "    correct = 0\n",
        "    total = len(labels) # Total number of windows\n",
        "\n",
        "    # Ensure labels and predictions have the same length\n",
        "    if len(labels) != len(predictions):\n",
        "        print(\"Warning: Length of labels and predictions do not match.\")\n",
        "        # Adjust total to the minimum length if lengths differ\n",
        "        total = min(len(labels), len(predictions))\n",
        "        labels = labels[:total]\n",
        "        predictions = predictions[:total]\n",
        "\n",
        "\n",
        "    for pred, label in zip(predictions, labels):\n",
        "        # Now comparing individual predictions and labels\n",
        "        if pred == label:\n",
        "            correct += 1\n",
        "    return correct / total\n",
        "\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    \"\"\"Evaluate the sliding window model\"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "            windows = batch['window'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            logits = model(windows)\n",
        "            probabilities = torch.sigmoid(logits)\n",
        "            predictions = (probabilities > 0.5).long()\n",
        "\n",
        "            all_preds.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_probs.extend(probabilities.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=['No Signal', 'Signal']))\n",
        "\n",
        "    f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
        "    f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
        "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    seq_acc = sequence_level_accuracy(all_labels, all_preds)\n",
        "\n",
        "    print(f\"F1 Score (weighted): {f1_weighted:.4f}\")\n",
        "    print(f\"F1 Score (macro): {f1_macro:.4f}\")\n",
        "    print(f\"Matthews Correlation Coefficient: {mcc:.4f}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Sequence-level Accuracy: {seq_acc:.4f}\")\n",
        "\n",
        "    return all_preds, all_labels, all_probs\n",
        "\n",
        "def predict_sequence(model, sequence, window_size, device, threshold=0.5):\n",
        "    \"\"\"Predict signal peptide positions for a full sequence\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Create dummy labels (we don't need them for prediction)\n",
        "    dummy_labels = [0] * len(sequence)\n",
        "\n",
        "    # Create sliding windows\n",
        "    windows, _, positions = create_sliding_windows(sequence, dummy_labels, window_size, stride=1)\n",
        "\n",
        "    # Encode windows\n",
        "    encoded_windows = get_protbert_window_embeddings(windows)\n",
        "\n",
        "    predictions = []\n",
        "    probabilities = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for encoded_window in encoded_windows:\n",
        "            window_tensor = torch.tensor(encoded_window, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "            logit = model(window_tensor)\n",
        "            prob = torch.sigmoid(logit).item()\n",
        "            pred = int(prob > threshold)\n",
        "\n",
        "            predictions.append(pred)\n",
        "            probabilities.append(prob)\n",
        "\n",
        "    return predictions, probabilities, positions\n",
        "\n",
        "# Load and preprocess data with sliding windows\n",
        "# This will create windows and labels but NOT encode them yet\n",
        "# Assuming load_and_preprocess_data is defined elsewhere and returns windows, labels, seq_ids, df_balanced\n",
        "# Example dummy function (replace with your actual data loading logic):\n",
        "def load_and_preprocess_data(fasta_path):\n",
        "    # This is a placeholder. Replace with your actual data loading.\n",
        "    # It should return a list of window sequences, a list of corresponding labels,\n",
        "    # a list of original sequence IDs for each window, and a DataFrame.\n",
        "    # Example dummy data:\n",
        "    sequences = [\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\", \"ABCDEFGHIJKLMN\"] * 50 # Longer sequence\n",
        "    labels = [[1] * 15 + [0] * (len(seq) - 15) for seq in sequences] # Dummy labels\n",
        "\n",
        "    all_windows = []\n",
        "    all_window_labels = []\n",
        "    all_seq_ids = []\n",
        "    df_rows = []\n",
        "    window_counter = 0\n",
        "\n",
        "    for i, seq in enumerate(sequences):\n",
        "        seq_id = f\"seq_{i}\"\n",
        "        windows, window_labels, positions = create_sliding_windows(seq, labels[i], WINDOW_SIZE, STRIDE)\n",
        "        all_windows.extend(windows)\n",
        "        all_window_labels.extend(window_labels)\n",
        "        all_seq_ids.extend([seq_id] * len(windows))\n",
        "        # Create DataFrame rows\n",
        "        for j in range(len(windows)):\n",
        "             df_rows.append({'sequence_id': seq_id, 'window_index': j, 'window_sequence': windows[j], 'label': window_labels[j], 'position_in_sequence': positions[j]}) # Add position if needed\n",
        "             window_counter += 1\n",
        "\n",
        "    df_balanced = pd.DataFrame(df_rows)\n",
        "    df_balanced = df_balanced.set_index('sequence_id') # Set index to seq_id for splitting\n",
        "    # Ensure the index name is set explicitly\n",
        "    df_balanced.index.name = 'sequence_id'\n",
        "\n",
        "    print(f\"Created {len(all_windows)} sliding windows.\")\n",
        "    return all_windows, all_window_labels, all_seq_ids, df_balanced\n",
        "\n",
        "\n",
        "windows, labels, seq_ids, df_balanced = load_and_preprocess_data(FASTA_PATH)\n",
        "\n",
        "# --- Step 1: Pre-encode and Save Embeddings ---\n",
        "print(\"Encoding all windows...\")\n",
        "# Process windows in batches and save directly to disk\n",
        "embeddings_path = os.path.join(DRIVE_PATH, \"all_window_embeddings.npy\")\n",
        "labels_path = os.path.join(DRIVE_PATH, \"all_window_labels.npy\")\n",
        "df_balanced_path = os.path.join(DRIVE_PATH, \"df_balanced.csv\") # Save the balanced dataframe for later use if needed\n",
        "\n",
        "# The embedding dimension is fixed by ProtBert-BFD\n",
        "embedding_dim = 1024 # ProtBert-BFD embedding dimension\n",
        "\n",
        "# Use the modified function to save embeddings incrementally\n",
        "all_embeddings = get_protbert_window_embeddings(\n",
        "    windows,\n",
        "    batch_size=BATCH_SIZE, # Use same batch size as for training/inference\n",
        "    output_path=embeddings_path,\n",
        "    embedding_dim=embedding_dim # Pass the known embedding dimension\n",
        ")\n",
        "\n",
        "# Save labels and balanced dataframe\n",
        "np.save(labels_path, np.array(labels))\n",
        "df_balanced.to_csv(df_balanced_path, index=False)\n",
        "\n",
        "print(f\"Embeddings saved to {embeddings_path}\")\n",
        "print(f\"Labels saved to {labels_path}\")\n",
        "print(f\"Balanced DataFrame saved to {df_balanced_path}\")\n",
        "\n",
        "# --- Step 2 & 3: Create Dataset instances using LazySlidingWindowDataset and Update Training/Evaluation ---\n",
        "\n",
        "# Split indices based on unique sequence IDs to avoid data leakage\n",
        "unique_seq_ids = list(df_balanced.index.unique()) # Use index from df_balanced\n",
        "train_seq_ids, temp_seq_ids = train_test_split(unique_seq_ids, test_size=0.2, random_state=42)\n",
        "val_seq_ids, test_seq_ids = train_test_split(temp_seq_ids, test_size=0.5, random_state=42) # 0.5 of 0.2 = 0.1 test size\n",
        "\n",
        "# Get indices corresponding to each split based on the original df_balanced index\n",
        "train_indices = [i for i, seq_id in enumerate(seq_ids) if seq_id in train_seq_ids]\n",
        "val_indices = [i for i, seq_id in enumerate(seq_ids) if seq_id in val_seq_ids]\n",
        "test_indices = [i for i, seq_id in enumerate(seq_ids) if seq_id in test_seq_ids]\n",
        "\n",
        "print(f\"\\nTrain windows (indices): {len(train_indices)}\")\n",
        "print(f\"Validation windows (indices): {len(val_indices)}\")\n",
        "print(f\"Test windows (indices): {len(test_indices)}\")\n",
        "\n",
        "# Create datasets and loaders using the saved files and indices\n",
        "train_dataset = LazySlidingWindowDataset(embeddings_path, labels_path, train_indices)\n",
        "val_dataset = LazySlidingWindowDataset(embeddings_path, labels_path, val_indices)\n",
        "test_dataset = LazySlidingWindowDataset(embeddings_path, labels_path, test_indices)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Initialize model (CNN version)\n",
        "# Use the embedding dimension determined from the dummy encoding\n",
        "model = CNNLSTMSignalPeptideClassifier(\n",
        "    WINDOW_SIZE, embedding_dim, hidden_dim=128, num_layers=2\n",
        ").to(DEVICE)\n",
        "\n",
        "print(f\"\\nModel parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "# Train model\n",
        "train_losses, val_losses = train_model(model, train_loader, val_loader, EPOCHS, DEVICE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e58c926e",
      "metadata": {
        "id": "e58c926e"
      },
      "source": [
        "**Reasoning**:\n",
        "The `ValueError: Cannot load file containing pickled data when allow_pickle=False` indicates that the `.npy` file being loaded contains pickled Python objects, and `np.load` is being called with `allow_pickle=False`, which is the default and recommended for security. This happens because the dummy `load_and_preprocess_data` function I added for testing created a small, artificial DataFrame and lists, and `np.save` on these might result in pickling. The actual `load_and_preprocess_data` function (which was defined in a previous cell and seems to have been overwritten by the dummy one in the last execution) processes real FASTA data and should produce standard NumPy arrays/lists that don't require pickling when saved.\n",
        "\n",
        "The fix is to revert to the correct `load_and_preprocess_data` function definition and remove the dummy version. I will also ensure the `np.load` calls in `LazySlidingWindowDataset` explicitly set `allow_pickle=False` to maintain security and verify that the data being saved is not pickled. The error suggests the labels file might also be the issue, so I will ensure both `np.load` calls in the dataset class use `allow_pickle=False`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IBkXBfEe_rwJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBkXBfEe_rwJ",
        "outputId": "60a8e6dc-3726-45fa-e6b5-6f210489de2c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score, matthews_corrcoef, accuracy_score\n",
        "from sklearn.utils import resample\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "DEVICE = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MODEL_NAME = \"Rostlab/prot_bert\"\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# Hyperparameters\n",
        "NUM_CLASSES = 2  # Binary classification (0: no signal peptide, 1: signal peptide)\n",
        "MAX_LENGTH = 70 # max sequence has len 70 in unpartitioned dataset\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "LR = 0.001\n",
        "WINDOW_SIZE = 35  # sliding window (odd because model predicts center residue)\n",
        "STRIDE = 1  # Step size for sliding window\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/PBLRost/\"\n",
        "FASTA_PATH = os.path.join(DRIVE_PATH, \"data/complete_set_unpartitioned.fasta\")\n",
        "MODEL_PATH = os.path.join(DRIVE_PATH, \"models/2state_tran_lin_cnn.pt\")\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME, do_lower_case=False)\n",
        "encoder = BertModel.from_pretrained(MODEL_NAME)\n",
        "encoder.to(DEVICE)\n",
        "\n",
        "def create_sliding_windows(sequence, labels, window_size, stride=1):\n",
        "    \"\"\"Create sliding windows from sequence and corresponding labels\"\"\"\n",
        "    windows = []\n",
        "    window_labels = []\n",
        "    positions = []\n",
        "\n",
        "    # Pad sequence for edge cases\n",
        "    pad_size = window_size // 2 # so starts classification after padding, at first real encoding\n",
        "    padded_seq = 'X' * pad_size + sequence + 'X' * pad_size\n",
        "    padded_labels = [0] * pad_size + labels + [0] * pad_size\n",
        "\n",
        "    # Create sliding windows\n",
        "    for i in range(0, len(sequence), stride):\n",
        "        start_idx = i\n",
        "        end_idx = i + window_size\n",
        "\n",
        "        if end_idx <= len(padded_seq):\n",
        "            window_seq = padded_seq[start_idx:end_idx]\n",
        "            # Label for the center position of the window\n",
        "            center_idx = start_idx + pad_size # residue to predict\n",
        "            if center_idx < len(padded_labels):\n",
        "                center_label = padded_labels[center_idx]\n",
        "\n",
        "                windows.append(window_seq)\n",
        "                window_labels.append(center_label)\n",
        "                positions.append(i)  # Original position in sequence\n",
        "\n",
        "    return windows, window_labels, positions\n",
        "\n",
        "def load_and_preprocess_data(fasta_path):\n",
        "    \"\"\"Load FASTA data and preprocess for sliding window approach\"\"\"\n",
        "    records = []\n",
        "\n",
        "    with open(fasta_path, \"r\") as f:\n",
        "        current_record = None\n",
        "        for line in f:\n",
        "            if line.startswith(\">\"):\n",
        "                if current_record is not None:\n",
        "                    if current_record[\"sequence\"] is not None and current_record[\"label\"] is not None:\n",
        "                        records.append(current_record)\n",
        "\n",
        "                uniprot_ac, kingdom, type_ = line[1:].strip().split(\"|\")\n",
        "                current_record = {\n",
        "                    \"uniprot_ac\": uniprot_ac,\n",
        "                    \"kingdom\": kingdom,\n",
        "                    \"type\": type_,\n",
        "                    \"sequence\": None,\n",
        "                    \"label\": None\n",
        "                }\n",
        "            else:\n",
        "                if current_record[\"sequence\"] is None:\n",
        "                    current_record[\"sequence\"] = line.strip()\n",
        "                elif current_record[\"label\"] is None:\n",
        "                    current_record[\"label\"] = line.strip()\n",
        "\n",
        "        # Add last record\n",
        "        if current_record is not None:\n",
        "            if current_record[\"sequence\"] is not None and current_record[\"label\"] is not None:\n",
        "                records.append(current_record)\n",
        "\n",
        "    print(f\"Total records loaded: {len(records)}\")\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df_raw = pd.DataFrame(records)\n",
        "\n",
        "    # Filter out sequences with 'P' in labels (if needed)\n",
        "    df = df_raw[~df_raw[\"label\"].str.contains(\"P\")]\n",
        "\n",
        "    # Map signal peptide types to binary classification\n",
        "    df[\"has_signal_peptide\"] = df[\"type\"].map({\n",
        "        \"NO_SP\": 0,\n",
        "        \"LIPO\": 1,\n",
        "        \"SP\": 1,\n",
        "        \"TAT\": 1,\n",
        "        \"TATLIPO\": 1\n",
        "    })\n",
        "\n",
        "    # Balance the dataset at sequence level first\n",
        "    df_majority = df[df[\"has_signal_peptide\"] == 0]\n",
        "    df_minority = df[df[\"has_signal_peptide\"] == 1]\n",
        "\n",
        "    if not df_minority.empty and not df_majority.empty:\n",
        "\n",
        "        n_samples = min(len(df_majority), 5000) # Limit samples to 5000 to prevent high ram usage\n",
        "        df_majority_sampled = resample(\n",
        "            df_majority,\n",
        "            replace=False, # sample without replacement\n",
        "            n_samples=n_samples,\n",
        "            random_state=42\n",
        "        )\n",
        "        df_balanced = pd.concat([df_majority_sampled, df_minority]) # Include all minority samples\n",
        "    else:\n",
        "        df_balanced = df.copy()\n",
        "\n",
        "\n",
        "    # Convert residue-level labels to binary\n",
        "    label_map = {'S': 1, 'T': 1, 'L': 1, 'I': 0, 'M': 0, 'O': 0}\n",
        "\n",
        "    # Create sliding windows for all sequences\n",
        "    all_windows = []\n",
        "    all_labels = []\n",
        "    all_seq_ids = []\n",
        "\n",
        "    for idx, row in df_balanced.iterrows():\n",
        "        sequence = row[\"sequence\"]\n",
        "        label_string = row[\"label\"]\n",
        "\n",
        "        # Convert label string to binary array\n",
        "        residue_labels = [label_map.get(c, 0) for c in label_string]\n",
        "\n",
        "        # Skip sequences where label length doesn't match sequence length\n",
        "        if len(residue_labels) != len(sequence):\n",
        "            print(\"A sequence length is not equal to the label length\")\n",
        "            continue\n",
        "\n",
        "        # Create sliding windows for this sequence\n",
        "        windows, window_labels, positions = create_sliding_windows(\n",
        "            sequence, residue_labels, WINDOW_SIZE, STRIDE\n",
        "        )\n",
        "\n",
        "        all_windows.extend(windows)\n",
        "        all_labels.extend(window_labels)\n",
        "        all_seq_ids.extend([idx] * len(windows))\n",
        "\n",
        "    print(f\"Total windows created: {len(all_windows)}\")\n",
        "    print(f\"Signal peptide windows: {sum(all_labels)}\")\n",
        "    print(f\"Non-signal peptide windows: {len(all_labels) - sum(all_labels)}\")\n",
        "\n",
        "    return all_windows, all_labels, all_seq_ids, df_balanced\n",
        "\n",
        "def get_protbert_window_embeddings(windows, batch_size=16, output_path=None, embedding_dim=1024):\n",
        "    \"\"\"\n",
        "    Output shape: (num_windows, window_size, embedding_dim)\n",
        "    If output_path is provided, saves embeddings to a memory-mapped file.\n",
        "    Otherwise, returns a concatenated NumPy array.\n",
        "    Slices to get embeddings for the WINDOW_SIZE amino acids.\n",
        "    \"\"\"\n",
        "    formatted = [\" \".join(list(window)) for window in windows] # needed for tokenization\n",
        "    num_windows = len(formatted)\n",
        "\n",
        "    # The actual sequence length after tokenization and slicing will be WINDOW_SIZE\n",
        "    target_seq_length = WINDOW_SIZE\n",
        "\n",
        "    if output_path:\n",
        "        # Initialize memory-mapped array with the correct sequence length\n",
        "        print(f\"Initializing memory-mapped file at {output_path} with shape ({num_windows}, {target_seq_length}, {embedding_dim})\")\n",
        "        all_embeddings_mmap = np.memmap(output_path, dtype='float32', mode='w+', shape=(num_windows, target_seq_length, embedding_dim))\n",
        "\n",
        "    all_embeddings_list = [] # Keep this for the case where output_path is None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, num_windows, batch_size)):\n",
        "            batch_seqs = formatted[i:i+batch_size]\n",
        "            # Use MAX_LENGTH for tokenizer max_length to handle longer sequences,\n",
        "            # but we will slice to WINDOW_SIZE afterwards.\n",
        "            encoded = tokenizer(batch_seqs, return_tensors=\"pt\", padding=True, truncation=True, max_length=MAX_LENGTH)\n",
        "\n",
        "            input_ids = encoded['input_ids'].to(DEVICE)\n",
        "            attention_mask = encoded['attention_mask'].to(DEVICE)\n",
        "\n",
        "            outputs = encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            batch_embeddings = outputs.last_hidden_state.cpu().numpy() # (batch, tokenized_seq_len, emb_dim)\n",
        "\n",
        "            # Slice to get embeddings for the WINDOW_SIZE amino acids (excluding [CLS] and [SEP])\n",
        "            # These are typically at indices 1 to WINDOW_SIZE in the tokenized sequence if not padded/truncated.\n",
        "            # If padded/truncated, the first WINDOW_SIZE relevant tokens might be padded.\n",
        "            # We need to be careful here. The model expects a fixed size input WINDOW_SIZE.\n",
        "            # Let's assume the slicing should always result in WINDOW_SIZE.\n",
        "            # If the tokenized sequence is shorter than WINDOW_SIZE + 2 after truncation,\n",
        "            # this slice might be out of bounds or return fewer than WINDOW_SIZE embeddings.\n",
        "            # Given MAX_LENGTH is 70 and WINDOW_SIZE is 35, a 35 AA window tokenizes to 37 tokens ([CLS], 35 AA, [SEP]).\n",
        "            # With padding/truncation to MAX_LENGTH=70, the output tensor will be shape (batch, 72, 1024).\n",
        "            # We want the 35 AA embeddings, which are at indices 1 to 36.\n",
        "            # So the slice should be [:, 1:WINDOW_SIZE+1, :]\n",
        "            processed_batch_embeddings = batch_embeddings[:, 1:WINDOW_SIZE+1, :] # Shape (batch, WINDOW_SIZE, emb_dim)\n",
        "\n",
        "\n",
        "            if output_path:\n",
        "                # Write directly to the memory-mapped array\n",
        "                end_idx = min(i + batch_size, num_windows)\n",
        "                # Ensure the batch size written matches the actual batch size\n",
        "                batch_size_actual = processed_batch_embeddings.shape[0]\n",
        "                all_embeddings_mmap[i:i+batch_size_actual] = processed_batch_embeddings # Handle the last batch size\n",
        "\n",
        "            else:\n",
        "                # Append to the list if not saving to file\n",
        "                for emb in processed_batch_embeddings:\n",
        "                    all_embeddings_list.append(emb)\n",
        "\n",
        "    if output_path:\n",
        "        # Ensure all changes are written to disk\n",
        "        all_embeddings_mmap.flush()\n",
        "        # The memory-mapped file will be returned. It behaves like a numpy array.\n",
        "        return all_embeddings_mmap\n",
        "    else:\n",
        "        # Return concatenated array\n",
        "        return np.stack(all_embeddings_list)\n",
        "\n",
        "\n",
        "class LazySlidingWindowDataset(Dataset):\n",
        "    def __init__(self, embeddings_path, labels_path, indices):\n",
        "        self.embeddings_path = embeddings_path\n",
        "        self.labels_path = labels_path\n",
        "        self.indices = indices # Indices corresponding to the split (train, val, or test)\n",
        "\n",
        "        # Load the full embeddings and labels once, ensure allow_pickle=False\n",
        "        self.all_embeddings = np.load(self.embeddings_path, mmap_mode='r', allow_pickle=False) # Use mmap_mode to avoid loading everything into memory\n",
        "        self.all_labels = np.load(self.labels_path, mmap_mode='r', allow_pickle=False)\n",
        "\n",
        "        # Ensure indices are within bounds (should be handled by splitting logic, but good practice)\n",
        "        if max(indices) >= len(self.all_labels) or min(indices) < 0:\n",
        "             raise ValueError(\"Indices are out of bounds for the loaded data.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the index in the original full dataset\n",
        "        original_idx = self.indices[idx]\n",
        "\n",
        "        # Load the specific embedding and label using the original index\n",
        "        # Slicing with numpy arrays loaded via mmap_mode='r' is efficient\n",
        "        embedding = self.all_embeddings[original_idx]\n",
        "        label = self.all_labels[original_idx]\n",
        "\n",
        "        return {\n",
        "            'window': torch.tensor(embedding, dtype=torch.float32),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "class CNNLSTMSignalPeptideClassifier(nn.Module):\n",
        "    def __init__(self, window_size, num_aa, hidden_dim=128, num_layers=2,\n",
        "                 cnn_channels=[64, 32], lstm_hidden=64, lstm_layers=2,\n",
        "                 use_bidirectional=True, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.window_size = window_size\n",
        "        self.num_aa = num_aa\n",
        "        self.use_bidirectional = use_bidirectional\n",
        "        self.lstm_hidden = lstm_hidden\n",
        "        self.lstm_layers = lstm_layers\n",
        "\n",
        "        # CNN layers for local pattern detection\n",
        "        self.conv_layers = nn.ModuleList()\n",
        "        in_channels = num_aa\n",
        "\n",
        "        for out_channels in cnn_channels:\n",
        "            self.conv_layers.append(nn.Sequential(\n",
        "                nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm1d(out_channels),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout)\n",
        "            ))\n",
        "            in_channels = out_channels\n",
        "\n",
        "        # LSTM layers for sequential dependencies\n",
        "        # Input to LSTM: [batch_size, seq_len, features]\n",
        "        lstm_input_size = cnn_channels[-1]  # Last CNN output channels\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=lstm_input_size,\n",
        "            hidden_size=lstm_hidden,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if lstm_layers > 1 else 0,\n",
        "            bidirectional=use_bidirectional\n",
        "        )\n",
        "\n",
        "        # Calculate LSTM output size\n",
        "        lstm_output_size = lstm_hidden * (2 if use_bidirectional else 1)\n",
        "\n",
        "        # Attention mechanism to focus on important positions\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(lstm_output_size, lstm_output_size // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(lstm_output_size // 2, 1)\n",
        "        )\n",
        "\n",
        "        # Final classification layers\n",
        "        classifier_layers = []\n",
        "        in_dim = lstm_output_size\n",
        "\n",
        "        for _ in range(num_layers):\n",
        "            classifier_layers.extend([\n",
        "                nn.Linear(in_dim, hidden_dim),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout)\n",
        "            ])\n",
        "            in_dim = hidden_dim\n",
        "\n",
        "        # Binary classification output\n",
        "        classifier_layers.append(nn.Linear(hidden_dim, 1))\n",
        "        self.classifier = nn.Sequential(*classifier_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, window_size, num_aa]\n",
        "        batch_size, seq_len, num_features = x.size()\n",
        "\n",
        "        # need [batch_size, num_aa, window_size] for Conv1d\n",
        "        x = x.transpose(1, 2)  # [batch_size, num_aa, window_size]\n",
        "\n",
        "        # Apply CNN layers\n",
        "        for conv_layer in self.conv_layers:\n",
        "            x = conv_layer(x)\n",
        "\n",
        "        # need [batch_size, seq_len, features] for LSTM\n",
        "        x = x.transpose(1, 2)  # [batch_size, window_size, cnn_channels[-1]]\n",
        "\n",
        "        # LSTM processing\n",
        "        lstm_out, (hidden, cell) = self.lstm(x)\n",
        "        # lstm_out: [batch_size, seq_len, lstm_hidden * directions]\n",
        "\n",
        "        # Apply attention mechanism\n",
        "        attention_weights = self.attention(lstm_out)  # [batch_size, seq_len, 1]\n",
        "        attention_weights = F.softmax(attention_weights, dim=1)\n",
        "\n",
        "        # Weighted sum of LSTM outputs\n",
        "        attended_output = torch.sum(lstm_out * attention_weights, dim=1)\n",
        "        # attended_output: [batch_size, lstm_hidden * directions]\n",
        "\n",
        "        # Final classification\n",
        "        logits = self.classifier(attended_output)\n",
        "        return logits.squeeze(-1)  # Remove last dimension\n",
        "\n",
        "\n",
        "class CNNLSTMSignalPeptideClassifierV2(nn.Module):\n",
        "    \"\"\"Alternative version with different CNN-LSTM integration\"\"\"\n",
        "    def __init__(self, window_size, num_aa, hidden_dim=128, num_layers=2,\n",
        "                 cnn_channels=[64, 32], lstm_hidden=64, lstm_layers=1,\n",
        "                 use_bidirectional=True, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.window_size = window_size\n",
        "        self.num_aa = num_aa\n",
        "\n",
        "        # CNN feature extractor\n",
        "        self.cnn_backbone = nn.Sequential(\n",
        "            # First conv block\n",
        "            nn.Conv1d(num_aa, cnn_channels[0], kernel_size=5, padding=2),\n",
        "            nn.BatchNorm1d(cnn_channels[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            # Second conv block\n",
        "            nn.Conv1d(cnn_channels[0], cnn_channels[1], kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(cnn_channels[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            # Third conv block\n",
        "            nn.Conv1d(cnn_channels[1], cnn_channels[1], kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(cnn_channels[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        # LSTM for sequential modeling\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=cnn_channels[-1],\n",
        "            hidden_size=lstm_hidden,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if lstm_layers > 1 else 0,\n",
        "            bidirectional=use_bidirectional\n",
        "        )\n",
        "\n",
        "        # Calculate dimensions\n",
        "        lstm_output_size = lstm_hidden * (2 if use_bidirectional else 1)\n",
        "\n",
        "        # Global pooling options\n",
        "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
        "\n",
        "        # Classification head\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(lstm_output_size, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim // 2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, window_size, num_aa]\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # CNN feature extraction\n",
        "        x = x.transpose(1, 2)  # [batch_size, num_aa, window_size]\n",
        "        cnn_features = self.cnn_backbone(x)\n",
        "\n",
        "        # Prepare for LSTM\n",
        "        x = cnn_features.transpose(1, 2)  # [batch_size, window_size, features]\n",
        "\n",
        "        # LSTM processing\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "\n",
        "        # Global pooling over sequence dimension\n",
        "        lstm_out = lstm_out.transpose(1, 2)  # [batch_size, features, seq_len]\n",
        "        pooled = self.global_pool(lstm_out).squeeze(-1)  # [batch_size, features]\n",
        "\n",
        "        # Classification\n",
        "        logits = self.classifier(pooled)\n",
        "        return logits.squeeze(-1)\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs, device,\n",
        "                        lr=0.001, weight_decay=1e-5, patience=5):\n",
        "    \"\"\"Enhanced training function with gradient clipping and better scheduling\"\"\"\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # More sophisticated learning rate scheduling\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', patience=patience, factor=0.5, verbose=True\n",
        "    )\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_batches = 0\n",
        "\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        for batch in progress_bar:\n",
        "            windows = batch['window'].to(device)\n",
        "            labels = batch['label'].to(device).float()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            try:\n",
        "                logits = model(windows)\n",
        "                loss = criterion(logits, labels)\n",
        "\n",
        "                loss.backward()\n",
        "\n",
        "                # Gradient clipping to prevent exploding gradients\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item()\n",
        "                train_batches += 1\n",
        "\n",
        "                progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                print(f\"Error in training batch: {e}\")\n",
        "                continue\n",
        "\n",
        "        if train_batches == 0:\n",
        "            print(\"No successful training batches!\")\n",
        "            break\n",
        "\n",
        "        avg_train_loss = train_loss / train_batches\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_batches = 0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                windows = batch['window'].to(device)\n",
        "                labels = batch['label'].to(device).float()\n",
        "\n",
        "                try:\n",
        "                    logits = model(windows)\n",
        "                    loss = criterion(logits, labels)\n",
        "\n",
        "                    val_loss += loss.item()\n",
        "                    val_batches += 1\n",
        "\n",
        "                    # Calculate accuracy\n",
        "                    predictions = (torch.sigmoid(logits) > 0.5).float()\n",
        "                    val_correct += (predictions == labels).sum().item()\n",
        "                    val_total += labels.size(0)\n",
        "\n",
        "                except RuntimeError as e:\n",
        "                    print(f\"Error in validation batch: {e}\")\n",
        "                    continue\n",
        "\n",
        "        if val_batches == 0:\n",
        "            print(\"No successful validation batches!\")\n",
        "            break\n",
        "\n",
        "        avg_val_loss = val_loss / val_batches\n",
        "        val_accuracy = val_correct / val_total\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        # Learning rate scheduling\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}, \"\n",
        "              f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
        "\n",
        "        # Early stopping and best model saving\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), MODEL_PATH)\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience * 2:  # More patience for complex model\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "    return train_losses, val_losses\n",
        "\n",
        "# compute percentage of false predicted labels\n",
        "def sequence_level_accuracy(labels, predictions):\n",
        "    \"\"\"Compute the accuracy of individual window predictions.\"\"\"\n",
        "    correct = 0\n",
        "    total = len(labels) # Total number of windows\n",
        "\n",
        "    # Ensure labels and predictions have the same length\n",
        "    if len(labels) != len(predictions):\n",
        "        print(\"Warning: Length of labels and predictions do not match.\")\n",
        "        # Adjust total to the minimum length if lengths differ\n",
        "        total = min(len(labels), len(predictions))\n",
        "        labels = labels[:total]\n",
        "        predictions = predictions[:total]\n",
        "\n",
        "\n",
        "    for pred, label in zip(predictions, labels):\n",
        "        # Now comparing individual predictions and labels\n",
        "        if pred == label:\n",
        "            correct += 1\n",
        "    return correct / total\n",
        "\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    \"\"\"Evaluate the sliding window model\"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "            windows = batch['window'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            logits = model(windows)\n",
        "            probabilities = torch.sigmoid(logits)\n",
        "            predictions = (probabilities > 0.5).long()\n",
        "\n",
        "            all_preds.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_probs.extend(probabilities.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=['No Signal', 'Signal']))\n",
        "\n",
        "    f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
        "    f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
        "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    seq_acc = sequence_level_accuracy(all_labels, all_preds)\n",
        "\n",
        "    print(f\"F1 Score (weighted): {f1_weighted:.4f}\")\n",
        "    print(f\"F1 Score (macro): {f1_macro:.4f}\")\n",
        "    print(f\"Matthews Correlation Coefficient: {mcc:.4f}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Sequence-level Accuracy: {seq_acc:.4f}\")\n",
        "\n",
        "    return all_preds, all_labels, all_probs\n",
        "\n",
        "def predict_sequence(model, sequence, window_size, device, threshold=0.5):\n",
        "    \"\"\"Predict signal peptide positions for a full sequence\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Create dummy labels (we don't need them for prediction)\n",
        "    dummy_labels = [0] * len(sequence)\n",
        "\n",
        "    # Create sliding windows\n",
        "    windows, _, positions = create_sliding_windows(sequence, dummy_labels, window_size, stride=1)\n",
        "\n",
        "    # Encode windows\n",
        "    # Note: This predict_sequence function still uses the get_protbert_window_embeddings\n",
        "    # without the output_path, meaning it will load all embeddings into memory for prediction.\n",
        "    # For very long sequences, this might still cause high RAM usage.\n",
        "    # A better approach for prediction would be to process windows one by one or in small batches\n",
        "    # without saving to a memory-mapped file first.\n",
        "    encoded_windows = get_protbert_window_embeddings(windows)\n",
        "\n",
        "    predictions = []\n",
        "    probabilities = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for encoded_window in encoded_windows:\n",
        "            window_tensor = torch.tensor(encoded_window, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "            logit = model(window_tensor)\n",
        "            prob = torch.sigmoid(logit).item()\n",
        "            pred = int(prob > threshold)\n",
        "\n",
        "            predictions.append(pred)\n",
        "            probabilities.append(prob)\n",
        "\n",
        "    return predictions, probabilities, positions\n",
        "\n",
        "# Load and preprocess data with sliding windows\n",
        "# This will create windows and labels but NOT encode them yet\n",
        "windows, labels, seq_ids, df_balanced = load_and_preprocess_data(FASTA_PATH)\n",
        "\n",
        "# --- Step 1: Pre-encode and Save Embeddings ---\n",
        "print(\"Encoding all windows...\")\n",
        "# Process windows in batches and save directly to disk\n",
        "embeddings_path = os.path.join(DRIVE_PATH, \"all_window_embeddings.npy\")\n",
        "labels_path = os.path.join(DRIVE_PATH, \"all_window_labels.npy\")\n",
        "df_balanced_path = os.path.join(DRIVE_PATH, \"df_balanced.csv\") # Save the balanced dataframe for later use if needed\n",
        "\n",
        "# The embedding dimension is fixed by ProtBert-BFD\n",
        "embedding_dim = 1024 # ProtBert-BFD embedding dimension\n",
        "\n",
        "# Use the modified function to save embeddings incrementally\n",
        "all_embeddings = get_protbert_window_embeddings(\n",
        "    windows,\n",
        "    batch_size=BATCH_SIZE, # Use same batch size as for training/inference\n",
        "    output_path=embeddings_path,\n",
        "    embedding_dim=embedding_dim # Pass the known embedding dimension\n",
        ")\n",
        "\n",
        "# Save labels and balanced dataframe\n",
        "np.save(labels_path, np.array(labels))\n",
        "df_balanced.to_csv(df_balanced_path, index=False)\n",
        "\n",
        "print(f\"Embeddings saved to {embeddings_path}\")\n",
        "print(f\"Labels saved to {labels_path}\")\n",
        "print(f\"Balanced DataFrame saved to {df_balanced_path}\")\n",
        "\n",
        "# --- Step 2 & 3: Create Dataset instances using LazySlidingWindowDataset and Update Training/Evaluation ---\n",
        "\n",
        "# Split indices based on unique sequence IDs to avoid data leakage\n",
        "unique_seq_ids = list(df_balanced.index.unique()) # Use index from df_balanced\n",
        "train_seq_ids, temp_seq_ids = train_test_split(unique_seq_ids, test_size=0.2, random_state=42)\n",
        "val_seq_ids, test_seq_ids = train_test_split(temp_seq_ids, test_size=0.5, random_state=42) # 0.5 of 0.2 = 0.1 test size\n",
        "\n",
        "# Get indices corresponding to each split based on the original df_balanced index\n",
        "train_indices = [i for i, seq_id in enumerate(seq_ids) if seq_id in train_seq_ids]\n",
        "val_indices = [i for i, seq_id in enumerate(seq_ids) if seq_id in val_seq_ids]\n",
        "test_indices = [i for i, seq_id in enumerate(seq_ids) if seq_id in test_seq_ids]\n",
        "\n",
        "print(f\"\\nTrain windows (indices): {len(train_indices)}\")\n",
        "print(f\"Validation windows (indices): {len(val_indices)}\")\n",
        "print(f\"Test windows (indices): {len(test_indices)}\")\n",
        "\n",
        "# Create datasets and loaders using the saved files and indices\n",
        "train_dataset = LazySlidingWindowDataset(embeddings_path, labels_path, train_indices)\n",
        "val_dataset = LazySlidingWindowDataset(embeddings_path, labels_path, val_indices)\n",
        "test_dataset = LazySlidingWindowDataset(embeddings_path, labels_path, test_indices)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Initialize model (CNN version)\n",
        "model = CNNLSTMSignalPeptideClassifier(\n",
        "    WINDOW_SIZE, embedding_dim, hidden_dim=128, num_layers=2\n",
        ").to(DEVICE)\n",
        "\n",
        "print(f\"\\nModel parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "# Train model\n",
        "train_losses, val_losses = train_model(model, train_loader, val_loader, EPOCHS, DEVICE)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
