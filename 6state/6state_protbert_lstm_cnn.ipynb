{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fb673bb6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb673bb6",
        "outputId": "b1bc6927-e94f-4331-eb18-d13c80004075"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: mps\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name '__file__' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m LR \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m\n\u001b[1;32m     17\u001b[0m NUM_FOLDS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m---> 19\u001b[0m BASE_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18;43m__file__\u001b[39;49m))\n\u001b[1;32m     20\u001b[0m DATA_PATH \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(BASE_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/aufgabe3/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m DATA_PATH_FOLDS \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATA_PATH, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5-fold/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
          ]
        }
      ],
      "source": [
        "import tqdm as notebook_tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "MODEL_NAME = \"Rostlab/prot_bert\"\n",
        "DEVICE = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "NUM_CLASSES = 6  # num classes for classification\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "LR = 0.001\n",
        "NUM_FOLDS = 5\n",
        "\n",
        "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
        "DATA_PATH = os.path.join(BASE_DIR, \"../data/aufgabe3/\")\n",
        "DATA_PATH_FOLDS = os.path.join(DATA_PATH, \"5-fold/\")\n",
        "MODEL_SAVE_PATH_TEMP = os.path.join(BASE_DIR, \"../models/6state_protbert_lstm_cnn_fold{}.pt\")\n",
        "MODEL_SAVE_PATH = os.path.join(BASE_DIR, \"../models/6state_protbert_lstm_cnn.pt\")\n",
        "TRAIN_VAL_LOSSES_DATA_SAVE_PATH = os.path.join(DATA_PATH, \"outputs/\")\n",
        "TEST_CSV = os.path.join(DATA_PATH, \"reduced_30_signalP6_test.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abc30469",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "abc30469",
        "outputId": "7bb406f1-378a-477e-91df-b7bc57d561b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading test data...\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/data/aufgabe3/reduced_30_signalP6_test.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading test data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m test_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTEST_CSV\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest records: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m test_df\u001b[38;5;241m.\u001b[39mhead()\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/aufgabe3/reduced_30_signalP6_test.csv'"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"Loading test data...\")\n",
        "test_df = pd.read_csv(TEST_CSV)\n",
        "print(f\"Test records: {len(test_df)}\")\n",
        "\n",
        "test_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06c475a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "06c475a3",
        "outputId": "4b203a3f-d448-4154-edb3-37c5bc7a314e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing test data...\n",
            "Test records after filtering: 3410\n",
            "Test sequences: 3410\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"test_df_encoded\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1184.6571233905615,\n        \"min\": 0.0,\n        \"max\": 3410.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3410.0,\n          70.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7f53f29a-0e97-4618-b979-45c40bea9d74\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3410.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f53f29a-0e97-4618-b979-45c40bea9d74')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7f53f29a-0e97-4618-b979-45c40bea9d74 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7f53f29a-0e97-4618-b979-45c40bea9d74');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e703a0b6-e759-44ee-8061-988db6668534\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e703a0b6-e759-44ee-8061-988db6668534')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e703a0b6-e759-44ee-8061-988db6668534 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       length\n",
              "count  3410.0\n",
              "mean     70.0\n",
              "std       0.0\n",
              "min      70.0\n",
              "25%      70.0\n",
              "50%      70.0\n",
              "75%      70.0\n",
              "max      70.0"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_map = {'S': 0, 'T': 1, 'L': 2, 'I': 3, 'M': 4, 'O': 5}\n",
        "\n",
        "print(\"\\nProcessing test data...\")\n",
        "test_df_filtered = test_df[~test_df[\"labels\"].str.contains(\"P\", na=False)]\n",
        "print(f\"Test records after filtering: {len(test_df_filtered)}\")\n",
        "\n",
        "test_df_filtered.describe()\n",
        "\n",
        "test_df_encoded = test_df_filtered.copy()\n",
        "test_df_encoded[\"label\"] = test_df_encoded[\"labels\"].apply(lambda x: [label_map[c] for c in x if c in label_map])\n",
        "test_df_encoded = test_df_encoded[test_df_encoded[\"label\"].map(len) > 0]\n",
        "test_seqs = test_df_encoded[\"sequence\"].tolist()\n",
        "test_label_seqs = test_df_encoded[\"label\"].tolist()\n",
        "\n",
        "print(f\"Test sequences: {len(test_seqs)}\")\n",
        "test_df_encoded.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86d69cb6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86d69cb6",
        "outputId": "7f6466ec-5b91-4dbb-bc8d-fd313d673856"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30, 1024, padding_idx=0)\n",
              "    (position_embeddings): Embedding(40000, 1024)\n",
              "    (token_type_embeddings): Embedding(2, 1024)\n",
              "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.0, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-29): 30 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSdpaSelfAttention(\n",
              "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME, do_lower_case=False)\n",
        "encoder = BertModel.from_pretrained(MODEL_NAME)\n",
        "encoder.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63d54f7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63d54f7c",
        "outputId": "dbfe5bf7-39ab-4109-b455-e76866a9393d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test data prepared: 3410 sequences\n"
          ]
        }
      ],
      "source": [
        "class SPDataset(Dataset):\n",
        "    def __init__(self, sequences, label_seqs, label_map):\n",
        "        self.label_map = label_map\n",
        "        self.label_seqs = label_seqs\n",
        "        self.sequences = sequences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.sequences[idx]\n",
        "        seq_processed = \" \".join(list(seq))\n",
        "        labels = self.label_seqs[idx]\n",
        "\n",
        "        encoded = tokenizer(seq_processed, return_tensors=\"pt\",\n",
        "                            padding=\"max_length\", truncation=True, max_length=512)\n",
        "        input_ids = encoded['input_ids'].squeeze(0)\n",
        "        attention_mask = encoded['attention_mask'].squeeze(0)\n",
        "\n",
        "        # Build label tensor accounting for [CLS], sequence, [SEP], [PAD]\n",
        "        token_labels = [-100]  # [CLS]\n",
        "\n",
        "        for label in labels:\n",
        "            token_labels.append(label)\n",
        "\n",
        "        token_labels.append(-100)  # [SEP]\n",
        "\n",
        "        # Pad to max_length\n",
        "        while len(token_labels) < input_ids.size(0):\n",
        "            token_labels.append(-100)\n",
        "\n",
        "        # Truncate if needed\n",
        "        token_labels = token_labels[:input_ids.size(0)]\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'labels': torch.tensor(token_labels)\n",
        "        }\n",
        "\n",
        "# Test dataset (not yet needed)\n",
        "test_dataset = SPDataset(test_seqs, test_label_seqs, label_map)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(f\"\\nTest data prepared: {len(test_seqs)} sequences\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e43de5ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e43de5ab",
        "outputId": "a2877a53-a7e2-4514-dc08-d1248a8e6890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytorch-crf\n",
            "  Downloading pytorch_crf-0.7.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-crf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchcrf import CRF\n",
        "\n",
        "class SPCNNClassifier(nn.Module):\n",
        "    def __init__(self, encoder_model, num_labels):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder_model\n",
        "        self.dropout = nn.Dropout(0.35)\n",
        "        hidden_size = self.encoder.config.hidden_size\n",
        "\n",
        "        self.conv = nn.Conv1d(in_channels=hidden_size, out_channels=1024, kernel_size=5, padding=2)\n",
        "        # Normalize the conv output (should expect shape: (batch, 1024, seq_len))\n",
        "        self.bn_conv = nn.BatchNorm1d(1024)\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=1024, hidden_size=512, num_layers=2, bidirectional=True, batch_first=True)\n",
        "        # 1 dense layer\n",
        "        self.classifier = nn.Linear(512 * 2, num_labels)\n",
        "        self.crf = CRF(num_labels, batch_first=True)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "\n",
        "        # encoded with bert\n",
        "        encoder_output = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_states = encoder_output.last_hidden_state  # (batch, seq_len, hidden_size)\n",
        "\n",
        "        # Apply conv, then batch normalization and ReLU\n",
        "        x_conv = self.conv(hidden_states.transpose(1, 2))  # (batch, 1024, seq_len)\n",
        "        x_conv = self.bn_conv(x_conv)\n",
        "        x_conv = F.relu_(x_conv)                          # (batch, 1024, seq_len)\n",
        "\n",
        "        # Transpose CNN output for lstm: (batch, seq_len, features)\n",
        "        x_lstm_input = x_conv.transpose(1, 2)           # (batch, seq_len, 1024)\n",
        "\n",
        "        # Apply lstm\n",
        "        lstm_out, _ = self.lstm(x_lstm_input)            # (batch, seq_len, 1024)\n",
        "\n",
        "        # classifier to num_labels\n",
        "        x_linear = self.classifier(lstm_out)             # (batch, seq_len, num_labels)\n",
        "        logits = self.dropout(x_linear)                  # (batch, seq_len, num_labels)\n",
        "\n",
        "        if labels is not None:\n",
        "            # Replace ignore-index (-100) with a valid label (0) (crf doesn't support -100)\n",
        "            mod_labels = labels.clone()\n",
        "            mod_labels[labels == -100] = 0\n",
        "            loss = -self.crf(logits, mod_labels, mask=attention_mask.bool(), reduction='mean')\n",
        "            return loss\n",
        "        else:\n",
        "            predictions = self.crf.decode(logits, mask=attention_mask.bool())\n",
        "            return predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e0d88fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e0d88fd",
        "outputId": "fa07159c-2513-4a69-d93f-b462840039c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data preparation function ready\n"
          ]
        }
      ],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# load and prepare data for a specific fold\n",
        "def prepare_fold_data(fold_num):\n",
        "\n",
        "    train_csv = os.path.join(DATA_PATH_FOLDS, f\"fold_{fold_num}_train.csv\")\n",
        "    val_csv = os.path.join(DATA_PATH_FOLDS, f\"fold_{fold_num}_val.csv\")\n",
        "\n",
        "    print(f\"\\n=== Fold {fold_num} ===\")\n",
        "    print(f\"Loading training data from: {train_csv}\")\n",
        "    train_df = pd.read_csv(train_csv)\n",
        "    print(f\"Training records: {len(train_df)}\")\n",
        "\n",
        "    print(f\"Loading validation data from: {val_csv}\")\n",
        "    val_df = pd.read_csv(val_csv)\n",
        "    print(f\"Validation records: {len(val_df)}\")\n",
        "\n",
        "    # Filter data\n",
        "    train_df_filtered = train_df[~train_df[\"labels\"].str.contains(\"P\", na=False)]\n",
        "    val_df_filtered = val_df[~val_df[\"labels\"].str.contains(\"P\", na=False)]\n",
        "    print(f\"Training records after filtering: {len(train_df_filtered)}\")\n",
        "    print(f\"Validation records after filtering: {len(val_df_filtered)}\")\n",
        "\n",
        "    # Encode labels\n",
        "    train_df_encoded = train_df_filtered.copy()\n",
        "    train_df_encoded[\"label\"] = train_df_encoded[\"labels\"].apply(lambda x: [label_map[c] for c in x if c in label_map])\n",
        "    train_df_encoded = train_df_encoded[train_df_encoded[\"label\"].map(len) > 0]\n",
        "    train_seqs = train_df_encoded[\"sequence\"].tolist()\n",
        "    train_label_seqs = train_df_encoded[\"label\"].tolist()\n",
        "    print(\"Encoded train data:\")\n",
        "    train_df_encoded.head()\n",
        "\n",
        "    val_df_encoded = val_df_filtered.copy()\n",
        "    val_df_encoded[\"label\"] = val_df_encoded[\"labels\"].apply(lambda x: [label_map[c] for c in x if c in label_map])\n",
        "    val_df_encoded = val_df_encoded[val_df_encoded[\"label\"].map(len) > 0]\n",
        "    val_seqs = val_df_encoded[\"sequence\"].tolist()\n",
        "    val_label_seqs = val_df_encoded[\"label\"].tolist()\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = SPDataset(train_seqs, train_label_seqs, label_map)\n",
        "    val_dataset = SPDataset(val_seqs, val_label_seqs, label_map)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    print(f\"Fold {fold_num} prepared: {len(train_seqs)} train, {len(val_seqs)} val sequences\")\n",
        "\n",
        "    return train_loader, val_loader, train_seqs, val_seqs\n",
        "\n",
        "print(\"Data preparation function ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d562c26",
      "metadata": {
        "id": "4d562c26"
      },
      "outputs": [],
      "source": [
        "# sequence-level accuracy, skipping -100 (ignored) positions\n",
        "def sequence_level_accuracy(preds_flat, labels_flat, test_label_seqs):\n",
        "    # reconstruct the sequences from the flat predictions\n",
        "    seq_lengths = [len(seq) for seq in test_label_seqs]\n",
        "    preds_seq = []\n",
        "    labels_seq = []\n",
        "    idx = 0\n",
        "    for l in seq_lengths:\n",
        "        preds_seq.append(preds_flat[idx:idx+l])\n",
        "        labels_seq.append(labels_flat[idx:idx+l])\n",
        "        idx += l\n",
        "\n",
        "    # check if the valid predictions match the labels\n",
        "    correct = 0\n",
        "    for pred, label in zip(preds_seq, labels_seq):\n",
        "        is_valid = [l != -100 for l in label]\n",
        "        valid_preds = [p for p, valid in zip(pred, is_valid) if valid]\n",
        "        valid_labels = [l for l, valid in zip(label, is_valid) if valid]\n",
        "        if valid_preds == valid_labels:\n",
        "            correct += 1\n",
        "\n",
        "    total = len(seq_lengths)\n",
        "    return correct / total if total > 0 else 0.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d3bc313",
      "metadata": {
        "id": "9d3bc313"
      },
      "outputs": [],
      "source": [
        "\n",
        "def encoder_unfreeze(model, epoch):\n",
        "    if epoch < 2:\n",
        "        # Freeze encoder completely\n",
        "        for param in model.encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "        trainable = 0\n",
        "\n",
        "    elif epoch < 4:\n",
        "        # Unfreeze last 6 layers\n",
        "        for param in model.encoder.embeddings.parameters():\n",
        "            param.requires_grad = False\n",
        "        for layer in model.encoder.encoder.layer[:-6]:\n",
        "            for param in layer.parameters():\n",
        "                param.requires_grad = False\n",
        "        for layer in model.encoder.encoder.layer[-6:]:\n",
        "            for param in layer.parameters():\n",
        "                param.requires_grad = True\n",
        "        trainable = 6\n",
        "\n",
        "    else:\n",
        "        # Unfreeze all (but use very low LR)\n",
        "        for param in model.encoder.parameters():\n",
        "            param.requires_grad = True\n",
        "        trainable = len(model.encoder.encoder.layer)\n",
        "\n",
        "    print(f\"Epoch {epoch}: {trainable}/{len(model.encoder.encoder.layer)} encoder layers trainable\")\n",
        "    return trainable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d159eaca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d159eaca",
        "outputId": "33eceac2-0a5c-48f0-8037-65e0c73ec41b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Starting Fold 1/5\n",
            "============================================================\n",
            "\n",
            "=== Fold 1 ===\n",
            "Loading training data from: /content/drive/MyDrive/PBLRost/data/reduced_30/5-fold/fold_1_train.csv\n",
            "Training records: 10940\n",
            "Loading validation data from: /content/drive/MyDrive/PBLRost/data/reduced_30/5-fold/fold_1_val.csv\n",
            "Validation records: 2735\n",
            "Training records after filtering: 10920\n",
            "Validation records after filtering: 2730\n",
            "Encoded train data:\n",
            "Fold 1 prepared: 10920 train, 2730 val sequences\n",
            "Epoch 0: 0/30 encoder layers trainable\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fold 1 - Epoch 1/10 [Train]: 100%|██████████| 342/342 [28:01<00:00,  4.92s/batch, loss=21.5]\n",
            "Fold 1 - Epoch 1/10 [Val]: 100%|██████████| 86/86 [05:55<00:00,  4.13s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 - Epoch 1/10 - Train Loss: 34.1903, Val Loss: 10.2134\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from torch.amp import autocast, GradScaler\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "# Store results for all folds\n",
        "fold_results = {\n",
        "    'train_losses': [],\n",
        "    'val_losses': [],\n",
        "    'best_val_losses': [],\n",
        "    'fold_numbers': []\n",
        "}\n",
        "\n",
        "# Cross Validation Training Loop\n",
        "for fold in range(1, NUM_FOLDS + 1):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Starting Fold {fold}/{NUM_FOLDS}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Prepare data for this fold\n",
        "    train_loader, val_loader, train_seqs, val_seqs = prepare_fold_data(fold)\n",
        "\n",
        "    # Initialize fresh model for each fold\n",
        "    encoder_fold = BertModel.from_pretrained(MODEL_NAME)\n",
        "    encoder_fold.to(DEVICE)\n",
        "    model = SPCNNClassifier(encoder_fold, NUM_CLASSES).to(DEVICE)\n",
        "\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    # Track losses for this fold\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    # Training loop for this fold\n",
        "    for epoch in range(EPOCHS):\n",
        "        trainable_layers = encoder_unfreeze(model, epoch)\n",
        "\n",
        "        # Create optimizer based on current trainable parameters\n",
        "        if trainable_layers == 0:\n",
        "            # train head\n",
        "            optimizer = torch.optim.AdamW([\n",
        "                {\"params\": model.conv.parameters(), \"lr\": 1e-3},\n",
        "                {\"params\": model.classifier.parameters(), \"lr\": 1e-3},\n",
        "                {\"params\": model.lstm.parameters(), \"lr\": 1e-3},\n",
        "                {\"params\": model.crf.parameters(), \"lr\": 1e-3},\n",
        "            ])\n",
        "        elif trainable_layers == 6:\n",
        "            # train head + top layers\n",
        "            optimizer = torch.optim.AdamW([\n",
        "                {\"params\": model.encoder.encoder.layer[-6:].parameters(), \"lr\": 1e-5},\n",
        "                {\"params\": model.conv.parameters(), \"lr\": 5e-4},\n",
        "                {\"params\": model.classifier.parameters(), \"lr\": 5e-4},\n",
        "                {\"params\": model.lstm.parameters(), \"lr\": 5e-4},\n",
        "                {\"params\": model.crf.parameters(), \"lr\": 5e-4},\n",
        "            ])\n",
        "        else:\n",
        "            # Train all layers\n",
        "            optimizer = torch.optim.AdamW([\n",
        "                {\"params\": model.encoder.parameters(), \"lr\": 5e-6},\n",
        "                {\"params\": model.conv.parameters(), \"lr\": 1e-4},\n",
        "                {\"params\": model.classifier.parameters(), \"lr\": 1e-4},\n",
        "                {\"params\": model.lstm.parameters(), \"lr\": 1e-4},\n",
        "                {\"params\": model.crf.parameters(), \"lr\": 1e-4},\n",
        "            ])\n",
        "\n",
        "        # create scheduler for epoch\n",
        "        total_steps = len(train_loader)\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer,\n",
        "            num_warmup_steps=int(0.1 * total_steps),\n",
        "            num_training_steps=total_steps\n",
        "        )\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        pbar = tqdm(train_loader, desc=f\"Fold {fold} - Epoch {epoch+1}/{EPOCHS} [Train]\", unit=\"batch\")\n",
        "        total_train_loss = 0\n",
        "\n",
        "        for batch in pbar:\n",
        "            try:\n",
        "                input_ids = batch['input_ids'].to(DEVICE)\n",
        "                attention_mask = batch['attention_mask'].to(DEVICE)\n",
        "                token_labels = batch['labels'].to(DEVICE)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                loss = model(input_ids, attention_mask, token_labels)\n",
        "\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                scheduler.step()\n",
        "\n",
        "                total_train_loss += loss.item()\n",
        "                pbar.set_postfix(loss=loss.item())\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                print(\"Error during training:\", e)\n",
        "                gc.collect()\n",
        "                continue\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        val_batches = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_loader, desc=f\"Fold {fold} - Epoch {epoch+1}/{EPOCHS} [Val]\", unit=\"batch\"):\n",
        "                input_ids = batch['input_ids'].to(DEVICE)\n",
        "                attention_mask = batch['attention_mask'].to(DEVICE)\n",
        "                token_labels = batch['labels'].to(DEVICE)\n",
        "\n",
        "                loss = model(input_ids, attention_mask, token_labels)\n",
        "                total_val_loss += loss.item()\n",
        "                val_batches += 1\n",
        "\n",
        "        avg_val_loss = total_val_loss / val_batches if val_batches > 0 else 0\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        print(f\"Fold {fold} - Epoch {epoch+1}/{EPOCHS} - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        # Save best model for fold (temporary)\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            model_path_temp = MODEL_SAVE_PATH_TEMP.format(fold)\n",
        "            torch.save(model.state_dict(), model_path_temp)\n",
        "            print(f\"  → Best model for fold {fold} saved to {model_path_temp}\")\n",
        "\n",
        "    # Store results for fold\n",
        "    fold_results['train_losses'].append(train_losses)\n",
        "    fold_results['val_losses'].append(val_losses)\n",
        "    fold_results['best_val_losses'].append(best_val_loss)\n",
        "    fold_results['fold_numbers'].append(fold)\n",
        "\n",
        "    print(f\"\\nBest validation loss for fold {fold}: {best_val_loss:.4f}\")\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"K-Fold Cross Validation Complete!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nSummary of all folds:\")\n",
        "for i, best_loss in enumerate(fold_results['best_val_losses'], 1):\n",
        "    print(f\"Fold {i}: Best Validation Loss = {best_loss:.4f}\")\n",
        "\n",
        "avg_best_val_loss = sum(fold_results['best_val_losses']) / NUM_FOLDS\n",
        "print(f\"\\nAverage Best Validation Loss across all folds: {avg_best_val_loss:.4f}\")\n",
        "\n",
        "# Find best fold\n",
        "best_fold_idx = fold_results['best_val_losses'].index(min(fold_results['best_val_losses']))\n",
        "best_fold_num = fold_results['fold_numbers'][best_fold_idx]\n",
        "best_fold_loss = fold_results['best_val_losses'][best_fold_idx]\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Best performing fold: Fold {best_fold_num}\")\n",
        "print(f\"Best validation loss: {best_fold_loss:.4f}\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# best model saved to MODEL_SAVE_PATH\n",
        "import shutil\n",
        "best_model_path = MODEL_SAVE_PATH_TEMP.format(best_fold_num)\n",
        "shutil.copy(best_model_path, MODEL_SAVE_PATH)\n",
        "print(f\"\\nBest model (Fold {best_fold_num}) saved to: {MODEL_SAVE_PATH}\")\n",
        "\n",
        "# clean up of temporary fold models\n",
        "print(\"\\nTemporary fold models:\")\n",
        "for i in range(1, NUM_FOLDS + 1):\n",
        "    temp_path = MODEL_SAVE_PATH_TEMP.format(i)\n",
        "    if os.path.exists(temp_path):\n",
        "        print(f\"  - {temp_path}\")\n",
        "\n",
        "os.makedirs(TRAIN_VAL_LOSSES_DATA_SAVE_PATH, exist_ok=True)\n",
        "losses_pickle_path = os.path.join(TRAIN_VAL_LOSSES_DATA_SAVE_PATH, \"train_val_losses.pkl\")\n",
        "\n",
        "losses_data = {\n",
        "    'fold_numbers': fold_results['fold_numbers'],\n",
        "    'train_losses': fold_results['train_losses'],\n",
        "    'val_losses': fold_results['val_losses'],\n",
        "    'best_val_losses': fold_results['best_val_losses'],\n",
        "    'best_fold_num': best_fold_num,\n",
        "    'best_fold_loss': best_fold_loss,\n",
        "    'avg_best_val_loss': avg_best_val_loss,\n",
        "    'epochs': EPOCHS,\n",
        "    'num_folds': NUM_FOLDS\n",
        "}\n",
        "\n",
        "with open(losses_pickle_path, 'wb') as f:\n",
        "    pickle.dump(losses_data, f)\n",
        "\n",
        "print(f\"\\nTraining and validation losses saved to: {losses_pickle_path}\")\n",
        "print(f\"Data structure:\")\n",
        "print(f\"  - fold_numbers: list of fold IDs\")\n",
        "print(f\"  - train_losses: list of training losses per fold (each fold has {EPOCHS} epochs)\")\n",
        "print(f\"  - val_losses: list of validation losses per fold (each fold has {EPOCHS} epochs)\")\n",
        "print(f\"  - best_val_losses: list of best validation loss for each fold\")\n",
        "print(f\"  - best_fold_num: {best_fold_num}\")\n",
        "print(f\"  - best_fold_loss: {best_fold_loss:.4f}\")\n",
        "print(f\"  - avg_best_val_loss: {avg_best_val_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf5ec91f",
      "metadata": {
        "id": "cf5ec91f"
      },
      "outputs": [],
      "source": [
        "print(f\"\\n best model saved at: {MODEL_SAVE_PATH}, from fold {best_fold_num}, validation loss: {best_fold_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01c38879",
      "metadata": {
        "id": "01c38879"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from sklearn.metrics import classification_report, f1_score, matthews_corrcoef, accuracy_score, precision_score, recall_score\n",
        "\n",
        "# Load best model\n",
        "encoder_eval = BertModel.from_pretrained(MODEL_NAME)\n",
        "encoder_eval.to(DEVICE)\n",
        "model = SPCNNClassifier(encoder_eval, NUM_CLASSES).to(DEVICE)\n",
        "\n",
        "model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=DEVICE))\n",
        "print(f\"\\nModel loaded from {MODEL_SAVE_PATH}\")\n",
        "\n",
        "model.eval()\n",
        "test_loss = 0\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids'].to(DEVICE)\n",
        "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
        "        labels = batch['labels'].to(DEVICE)\n",
        "\n",
        "        # Compute loss using CRF\n",
        "        loss = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # Decode predictions using CRF\n",
        "        predictions = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Collect valid tokens\n",
        "        for pred_seq, label_seq, mask in zip(predictions, labels, attention_mask):\n",
        "            for pred, true, is_valid in zip(pred_seq, label_seq, mask):\n",
        "                if true.item() != -100 and is_valid.item() == 1:\n",
        "                    all_preds.append(pred)\n",
        "                    all_labels.append(true.item())\n",
        "\n",
        "# Calculate metrics\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Test Set Results\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=list(label_map.keys())))\n",
        "\n",
        "f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
        "f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
        "precision = precision_score(all_labels, all_preds, average=\"weighted\")\n",
        "recall = recall_score(all_labels, all_preds, average=\"weighted\")\n",
        "mcc = matthews_corrcoef(all_labels, all_preds)\n",
        "token_acc = accuracy_score(all_labels, all_preds)\n",
        "seq_acc = sequence_level_accuracy(all_preds, all_labels, test_label_seqs)\n",
        "avg_loss = test_loss / len(test_loader)\n",
        "\n",
        "print(f\"\\nMetrics Summary:\")\n",
        "print(f\"F1 Score (weighted): {f1_weighted:.4f}\")\n",
        "print(f\"F1 Score (macro): {f1_macro:.4f}\")\n",
        "print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")\n",
        "print(f\"Token-level Accuracy: {token_acc:.4f}\")\n",
        "print(f\"Sequence Level Accuracy: {seq_acc:.4f}\")\n",
        "print(f\"Average test loss: {avg_loss:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds, labels=list(label_map.values()))\n",
        "cm_relative = cm.astype(\"float\") / cm.sum(axis=1, keepdims=True)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm_relative, display_labels=list(label_map.keys()))\n",
        "disp.plot(cmap=\"OrRd\", xticks_rotation=45)\n",
        "plt.title(f\"Confusion Matrix - Best Model (Fold {best_fold_num})\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
